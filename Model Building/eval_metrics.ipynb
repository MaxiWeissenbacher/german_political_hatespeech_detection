{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e73ce303-8fc1-440f-aaa9-663771b00436",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, matthews_corrcoef, precision_score, recall_score, accuracy_score, precision_recall_fscore_support, balanced_accuracy_score\n",
    "import pandas as pd\n",
    "from functools import reduce\n",
    "\n",
    "def f1_multiclass(labels, preds):    \n",
    "    f1_score_info = {\n",
    "      \"f1_micro\": f1_score(labels, preds, average='micro'),\n",
    "      \"f1_macro\": f1_score(labels, preds, average='macro'),\n",
    "      \"f1_weighted\": f1_score(labels, preds, average='weighted')\n",
    "      }\n",
    "    return f1_score_info\n",
    "\n",
    "def p_multiclass(labels, preds):\n",
    "    precision_info = {\n",
    "      \"precision_micro\": precision_score(labels, preds, average='micro'),\n",
    "      \"precision_macro\": precision_score(labels, preds, average='macro'),\n",
    "      \"precision_weighted\": precision_score(labels, preds, average='weighted')}\n",
    "    return precision_info\n",
    "\n",
    "def recall_multiclass(labels, preds):\n",
    "    recall_info = {\n",
    "      \"recall_micro\": recall_score(labels, preds, average='micro'),\n",
    "      \"recall_macro\": recall_score(labels, preds, average='macro'),\n",
    "      \"recall_weighted\": recall_score(labels, preds, average='weighted')}\n",
    "    return recall_info\n",
    "\n",
    "def prepare_results(result_dict):\n",
    "    result_dict[\"f1_macro\"] = result_dict[\"f1\"][\"f1_macro\"]\n",
    "    result_dict[\"f1_micro\"] = result_dict[\"f1\"][\"f1_micro\"]\n",
    "    result_dict[\"f1_weighted\"] = result_dict[\"f1\"][\"f1_weighted\"]\n",
    "    \n",
    "    result_dict[\"precision_macro\"] = result_dict[\"precision\"][\"precision_macro\"]\n",
    "    result_dict[\"precision_micro\"] = result_dict[\"precision\"][\"precision_micro\"]\n",
    "    result_dict[\"precision_weighted\"] = result_dict[\"precision\"][\"precision_weighted\"]\n",
    "\n",
    "    result_dict[\"recall_macro\"] = result_dict[\"recall\"][\"recall_macro\"]\n",
    "    result_dict[\"recall_micro\"] = result_dict[\"recall\"][\"recall_micro\"]\n",
    "    result_dict[\"recall_weighted\"] = result_dict[\"recall\"][\"recall_weighted\"]\n",
    "\n",
    "    del result_dict[\"recall\"]\n",
    "    del result_dict[\"precision\"]\n",
    "    del result_dict[\"f1\"]\n",
    "\n",
    "    p_per_class = result_dict[\"prfs\"][0]\n",
    "    r_per_class = result_dict[\"prfs\"][1]\n",
    "    f_per_class = result_dict[\"prfs\"][2]\n",
    "    sample_per_class = result_dict[\"prfs\"][3]\n",
    "\n",
    "    i = 0\n",
    "    for number in p_per_class:\n",
    "        result_dict[\"precision_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    for number in r_per_class:\n",
    "        result_dict[\"recall_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    for number in f_per_class:\n",
    "        result_dict[\"f1_score_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    for number in sample_per_class:\n",
    "        result_dict[\"sample_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    del result_dict[\"prfs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "382f3c43-0cb2-4d8b-a5de-d7ea90b3c7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_to_df(d):\n",
    "    df=pd.DataFrame(d.items())\n",
    "    df.set_index(0, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d08931b5-a596-4794-901b-a4c5f101ed95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hello():\n",
    "    print(\"Hello World!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "911bb7fa-4406-44c8-ab54-5cbc86038505",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack_model(model_path='',file_name=''):\n",
    "    \n",
    "    files = [files for root, dirs, files in os.walk(model_path)][0]\n",
    "    with tarfile.open(file_name+ '.tar.gz', 'w:gz') as f:\n",
    "        for file in files:\n",
    "              f.add(f'{model_path}/{file}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed21615a-1616-4f9a-a64d-c98a2bd1d6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_model(model_name=''):\n",
    "    tar = tarfile.open(f\"{model_name}.tar.gz\", \"r:gz\")\n",
    "    tar.extractall()\n",
    "    tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c276f143-7999-417c-a13b-19760c6bef62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_results(result_dict):\n",
    "    result_dict[\"f1_macro\"] = result_dict[\"f1\"][\"f1_macro\"]\n",
    "    result_dict[\"f1_micro\"] = result_dict[\"f1\"][\"f1_micro\"]\n",
    "    result_dict[\"f1_weighted\"] = result_dict[\"f1\"][\"f1_weighted\"]\n",
    "\n",
    "    result_dict[\"precision_macro\"] = result_dict[\"precision\"][\"precision_macro\"]\n",
    "    result_dict[\"precision_micro\"] = result_dict[\"precision\"][\"precision_micro\"]\n",
    "    result_dict[\"precision_weighted\"] = result_dict[\"precision\"][\"precision_weighted\"]\n",
    "\n",
    "    result_dict[\"recall_macro\"] = result_dict[\"recall\"][\"recall_macro\"]\n",
    "    result_dict[\"recall_micro\"] = result_dict[\"recall\"][\"recall_micro\"]\n",
    "    result_dict[\"recall_weighted\"] = result_dict[\"recall\"][\"recall_weighted\"]\n",
    "\n",
    "    del result_dict[\"recall\"]\n",
    "    del result_dict[\"precision\"]\n",
    "    del result_dict[\"f1\"]\n",
    "\n",
    "    p_per_class = result_dict[\"prfs\"][0]\n",
    "    r_per_class = result_dict[\"prfs\"][1]\n",
    "    f_per_class = result_dict[\"prfs\"][2]\n",
    "    sample_per_class = result_dict[\"prfs\"][3]\n",
    "\n",
    "    i = 0\n",
    "    for number in p_per_class:\n",
    "        result_dict[\"precision_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    for number in r_per_class:\n",
    "        result_dict[\"recall_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    for number in f_per_class:\n",
    "        result_dict[\"f1_score_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    i = 0\n",
    "    for number in sample_per_class:\n",
    "        result_dict[\"sample_class_\" + str(i)] = number\n",
    "        i = i + 1\n",
    "\n",
    "    del result_dict[\"prfs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e45eebf8-c7cb-4332-b323-ce7005ba0fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def kfold_evaluation(ansatz):\n",
    "    file1 = pd.read_csv(F\"{ansatz}1.csv\")\n",
    "    file2 = pd.read_csv(F\"{ansatz}2.csv\")\n",
    "    file3 = pd.read_csv(F\"{ansatz}3.csv\")\n",
    "    file4 = pd.read_csv(F\"{ansatz}4.csv\")\n",
    "    file5 = pd.read_csv(F\"{ansatz}5.csv\")\n",
    "    \n",
    "    names = file1[\"0\"].tolist()\n",
    "    results = reduce(lambda a, b: a.add(b, fill_value=0), [file1[\"1\"], file2[\"1\"], file3[\"1\"], file4[\"1\"], file5[\"1\"]]).tolist()\n",
    "\n",
    "    results_divided = []\n",
    "    for i in results:\n",
    "        \n",
    "        res = i/5\n",
    "        results_divided.append(res)\n",
    "\n",
    "    d = {'Metrics':names,'Overall Results':results_divided}\n",
    "    overall_df = pd.DataFrame(d)\n",
    "    return overall_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
