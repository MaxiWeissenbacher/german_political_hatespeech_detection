{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88f1738e-73d4-48b2-a4f9-17f1e148a7ad",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5926dd6d-7280-4c13-9fff-a1f0a6104705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee39c446-2a44-4823-878e-fe8c65193491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Metrics</th>\n",
       "      <th>Overall Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>acc</td>\n",
       "      <td>0.773716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>bal_acc</td>\n",
       "      <td>0.739326</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Metrics  Overall Results\n",
       "0           0      acc         0.773716\n",
       "1           1  bal_acc         0.739326"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_base_german_cased = pd.read_csv(\"BASELINE_bert_base_german_cased.csv\")\n",
    "bert_base_multi_cased = pd.read_csv(\"BASELINE_bert_base_multilingual_cased.csv\")\n",
    "bert_base_multi_uncased = pd.read_csv(\"BASELINE_bert_base_multilingual_uncased.csv\")\n",
    "cardiff_xlm_roberta = pd.read_csv(\"BASELINE_cardiff_xlmroberta.csv\")\n",
    "dbmdz_bert_base_german_cased = pd.read_csv(\"BASELINE_dbmdz_bert_base_german_cased.csv\")\n",
    "dbmdz_bert_base_german_uncased = pd.read_csv(\"BASELINE_dbmdz_uncased.csv\")\n",
    "deepset_gbert_base = pd.read_csv(\"BASELINE_deepset_gbert_base.csv\")\n",
    "dehatebert_mono_german = pd.read_csv(\"BASELINE_dehatebert_mono_german.csv\")\n",
    "distilbert_base_german_cased = pd.read_csv(\"BASELINE_distilbert_base_german_cased.csv\")\n",
    "electra_german_uncased = pd.read_csv(\"BASELINE_electra_german_uncased.csv\")\n",
    "gbert_hasoc_2019 = pd.read_csv(\"BASELINE_gbert_hasoc_2019.csv\")\n",
    "german_toxicity = pd.read_csv(\"BASELINE_german_toxicity_classifier.csv\")\n",
    "roberta_t_systems = pd.read_csv(\"BASELINE_roberta_t_systems.csv\")\n",
    "xlm_roberta_base = pd.read_csv(\"BASELINE_xlm_roberta_base.csv\")\n",
    "xlm_roberta_base.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41b09b22-a23f-46c6-b408-000080e8ad16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bert-base-german-cased</th>\n",
       "      <th>bert-base-multilingual-cased</th>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <th>dbmdz-bert-base-german-cased</th>\n",
       "      <th>dbmdz-bert-base-german-uncased</th>\n",
       "      <th>deepset-gbert-base</th>\n",
       "      <th>dehatebert-mono-german</th>\n",
       "      <th>distilbert-base-german-cased</th>\n",
       "      <th>gbert-hasoc-2019</th>\n",
       "      <th>electra-german-uncased</th>\n",
       "      <th>xlm-roberta-base</th>\n",
       "      <th>cardiff-xlm-roberta-base</th>\n",
       "      <th>xlm-roberta-t-systems</th>\n",
       "      <th>german-toxicity-classifier</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metrics</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>acc</th>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.783240</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.805684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bal_acc</th>\n",
       "      <td>0.732440</td>\n",
       "      <td>0.688873</td>\n",
       "      <td>0.678968</td>\n",
       "      <td>0.717984</td>\n",
       "      <td>0.742982</td>\n",
       "      <td>0.749417</td>\n",
       "      <td>0.575248</td>\n",
       "      <td>0.732023</td>\n",
       "      <td>0.717156</td>\n",
       "      <td>0.764376</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>0.701237</td>\n",
       "      <td>0.731358</td>\n",
       "      <td>0.760148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mcc</th>\n",
       "      <td>0.470449</td>\n",
       "      <td>0.367920</td>\n",
       "      <td>0.378135</td>\n",
       "      <td>0.457526</td>\n",
       "      <td>0.507324</td>\n",
       "      <td>0.496862</td>\n",
       "      <td>0.149182</td>\n",
       "      <td>0.472484</td>\n",
       "      <td>0.466152</td>\n",
       "      <td>0.544674</td>\n",
       "      <td>0.475272</td>\n",
       "      <td>0.437749</td>\n",
       "      <td>0.488437</td>\n",
       "      <td>0.536026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_macro</th>\n",
       "      <td>0.732925</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.682305</td>\n",
       "      <td>0.724230</td>\n",
       "      <td>0.750871</td>\n",
       "      <td>0.745967</td>\n",
       "      <td>0.535920</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.728257</td>\n",
       "      <td>0.770875</td>\n",
       "      <td>0.736971</td>\n",
       "      <td>0.710270</td>\n",
       "      <td>0.740094</td>\n",
       "      <td>0.766381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_micro</th>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.783240</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.805684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_weighted</th>\n",
       "      <td>0.772278</td>\n",
       "      <td>0.719286</td>\n",
       "      <td>0.734648</td>\n",
       "      <td>0.770235</td>\n",
       "      <td>0.790340</td>\n",
       "      <td>0.782577</td>\n",
       "      <td>0.628200</td>\n",
       "      <td>0.774022</td>\n",
       "      <td>0.774304</td>\n",
       "      <td>0.806420</td>\n",
       "      <td>0.774242</td>\n",
       "      <td>0.759250</td>\n",
       "      <td>0.782932</td>\n",
       "      <td>0.802734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_macro</th>\n",
       "      <td>0.738523</td>\n",
       "      <td>0.679715</td>\n",
       "      <td>0.700926</td>\n",
       "      <td>0.740767</td>\n",
       "      <td>0.765142</td>\n",
       "      <td>0.748050</td>\n",
       "      <td>0.512370</td>\n",
       "      <td>0.740973</td>\n",
       "      <td>0.750372</td>\n",
       "      <td>0.780680</td>\n",
       "      <td>0.736056</td>\n",
       "      <td>0.739660</td>\n",
       "      <td>0.758342</td>\n",
       "      <td>0.776310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_micro</th>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.783240</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.805684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_weighted</th>\n",
       "      <td>0.774727</td>\n",
       "      <td>0.733360</td>\n",
       "      <td>0.737279</td>\n",
       "      <td>0.770149</td>\n",
       "      <td>0.790998</td>\n",
       "      <td>0.786120</td>\n",
       "      <td>0.598688</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.774474</td>\n",
       "      <td>0.806169</td>\n",
       "      <td>0.775912</td>\n",
       "      <td>0.764734</td>\n",
       "      <td>0.783621</td>\n",
       "      <td>0.802567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_macro</th>\n",
       "      <td>0.732440</td>\n",
       "      <td>0.688873</td>\n",
       "      <td>0.678968</td>\n",
       "      <td>0.717984</td>\n",
       "      <td>0.742982</td>\n",
       "      <td>0.749417</td>\n",
       "      <td>0.575248</td>\n",
       "      <td>0.732023</td>\n",
       "      <td>0.717156</td>\n",
       "      <td>0.764376</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>0.701237</td>\n",
       "      <td>0.731358</td>\n",
       "      <td>0.760148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_micro</th>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.783240</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.805684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_weighted</th>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.783240</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.805684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_class_0</th>\n",
       "      <td>0.643080</td>\n",
       "      <td>0.538564</td>\n",
       "      <td>0.605176</td>\n",
       "      <td>0.663425</td>\n",
       "      <td>0.697255</td>\n",
       "      <td>0.647879</td>\n",
       "      <td>0.285683</td>\n",
       "      <td>0.649726</td>\n",
       "      <td>0.687026</td>\n",
       "      <td>0.713744</td>\n",
       "      <td>0.631143</td>\n",
       "      <td>0.673909</td>\n",
       "      <td>0.691855</td>\n",
       "      <td>0.707172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>precision_class_1</th>\n",
       "      <td>0.833966</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>0.796676</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.833028</td>\n",
       "      <td>0.848221</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>0.832220</td>\n",
       "      <td>0.813719</td>\n",
       "      <td>0.847615</td>\n",
       "      <td>0.840968</td>\n",
       "      <td>0.805410</td>\n",
       "      <td>0.824828</td>\n",
       "      <td>0.845449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_class_0</th>\n",
       "      <td>0.623905</td>\n",
       "      <td>0.612950</td>\n",
       "      <td>0.509351</td>\n",
       "      <td>0.559859</td>\n",
       "      <td>0.607355</td>\n",
       "      <td>0.660329</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.615571</td>\n",
       "      <td>0.545696</td>\n",
       "      <td>0.646362</td>\n",
       "      <td>0.648905</td>\n",
       "      <td>0.523787</td>\n",
       "      <td>0.579069</td>\n",
       "      <td>0.640493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall_class_1</th>\n",
       "      <td>0.840975</td>\n",
       "      <td>0.764796</td>\n",
       "      <td>0.848585</td>\n",
       "      <td>0.876108</td>\n",
       "      <td>0.878608</td>\n",
       "      <td>0.838506</td>\n",
       "      <td>0.842162</td>\n",
       "      <td>0.848475</td>\n",
       "      <td>0.888616</td>\n",
       "      <td>0.882390</td>\n",
       "      <td>0.829748</td>\n",
       "      <td>0.878687</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.879803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_class_0</th>\n",
       "      <td>0.629384</td>\n",
       "      <td>0.565271</td>\n",
       "      <td>0.544632</td>\n",
       "      <td>0.603058</td>\n",
       "      <td>0.646985</td>\n",
       "      <td>0.649587</td>\n",
       "      <td>0.293761</td>\n",
       "      <td>0.628579</td>\n",
       "      <td>0.607160</td>\n",
       "      <td>0.677333</td>\n",
       "      <td>0.638915</td>\n",
       "      <td>0.581307</td>\n",
       "      <td>0.627441</td>\n",
       "      <td>0.670784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score_class_1</th>\n",
       "      <td>0.836466</td>\n",
       "      <td>0.788537</td>\n",
       "      <td>0.819979</td>\n",
       "      <td>0.845401</td>\n",
       "      <td>0.854757</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>0.778080</td>\n",
       "      <td>0.839359</td>\n",
       "      <td>0.849354</td>\n",
       "      <td>0.864417</td>\n",
       "      <td>0.835028</td>\n",
       "      <td>0.839233</td>\n",
       "      <td>0.852747</td>\n",
       "      <td>0.861977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_class_0</th>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "      <td>71.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_class_1</th>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "      <td>159.800000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    bert-base-german-cased  bert-base-multilingual-cased  \\\n",
       "Metrics                                                                    \n",
       "acc                               0.773761                      0.717641   \n",
       "bal_acc                           0.732440                      0.688873   \n",
       "mcc                               0.470449                      0.367920   \n",
       "f1_macro                          0.732925                      0.676904   \n",
       "f1_micro                          0.773761                      0.717641   \n",
       "f1_weighted                       0.772278                      0.719286   \n",
       "precision_macro                   0.738523                      0.679715   \n",
       "precision_micro                   0.773761                      0.717641   \n",
       "precision_weighted                0.774727                      0.733360   \n",
       "recall_macro                      0.732440                      0.688873   \n",
       "recall_micro                      0.773761                      0.717641   \n",
       "recall_weighted                   0.773761                      0.717641   \n",
       "precision_class_0                 0.643080                      0.538564   \n",
       "precision_class_1                 0.833966                      0.820865   \n",
       "recall_class_0                    0.623905                      0.612950   \n",
       "recall_class_1                    0.840975                      0.764796   \n",
       "f1_score_class_0                  0.629384                      0.565271   \n",
       "f1_score_class_1                  0.836466                      0.788537   \n",
       "sample_class_0                   71.800000                     71.800000   \n",
       "sample_class_1                  159.800000                    159.800000   \n",
       "\n",
       "                    bert-base-multilingual-uncased  \\\n",
       "Metrics                                              \n",
       "acc                                       0.743492   \n",
       "bal_acc                                   0.678968   \n",
       "mcc                                       0.378135   \n",
       "f1_macro                                  0.682305   \n",
       "f1_micro                                  0.743492   \n",
       "f1_weighted                               0.734648   \n",
       "precision_macro                           0.700926   \n",
       "precision_micro                           0.743492   \n",
       "precision_weighted                        0.737279   \n",
       "recall_macro                              0.678968   \n",
       "recall_micro                              0.743492   \n",
       "recall_weighted                           0.743492   \n",
       "precision_class_0                         0.605176   \n",
       "precision_class_1                         0.796676   \n",
       "recall_class_0                            0.509351   \n",
       "recall_class_1                            0.848585   \n",
       "f1_score_class_0                          0.544632   \n",
       "f1_score_class_1                          0.819979   \n",
       "sample_class_0                           71.800000   \n",
       "sample_class_1                          159.800000   \n",
       "\n",
       "                    dbmdz-bert-base-german-cased  \\\n",
       "Metrics                                            \n",
       "acc                                     0.778012   \n",
       "bal_acc                                 0.717984   \n",
       "mcc                                     0.457526   \n",
       "f1_macro                                0.724230   \n",
       "f1_micro                                0.778012   \n",
       "f1_weighted                             0.770235   \n",
       "precision_macro                         0.740767   \n",
       "precision_micro                         0.778012   \n",
       "precision_weighted                      0.770149   \n",
       "recall_macro                            0.717984   \n",
       "recall_micro                            0.778012   \n",
       "recall_weighted                         0.778012   \n",
       "precision_class_0                       0.663425   \n",
       "precision_class_1                       0.818108   \n",
       "recall_class_0                          0.559859   \n",
       "recall_class_1                          0.876108   \n",
       "f1_score_class_0                        0.603058   \n",
       "f1_score_class_1                        0.845401   \n",
       "sample_class_0                         71.800000   \n",
       "sample_class_1                        159.800000   \n",
       "\n",
       "                    dbmdz-bert-base-german-uncased  deepset-gbert-base  \\\n",
       "Metrics                                                                  \n",
       "acc                                       0.794451            0.783240   \n",
       "bal_acc                                   0.742982            0.749417   \n",
       "mcc                                       0.507324            0.496862   \n",
       "f1_macro                                  0.750871            0.745967   \n",
       "f1_micro                                  0.794451            0.783240   \n",
       "f1_weighted                               0.790340            0.782577   \n",
       "precision_macro                           0.765142            0.748050   \n",
       "precision_micro                           0.794451            0.783240   \n",
       "precision_weighted                        0.790998            0.786120   \n",
       "recall_macro                              0.742982            0.749417   \n",
       "recall_micro                              0.794451            0.783240   \n",
       "recall_weighted                           0.794451            0.783240   \n",
       "precision_class_0                         0.697255            0.647879   \n",
       "precision_class_1                         0.833028            0.848221   \n",
       "recall_class_0                            0.607355            0.660329   \n",
       "recall_class_1                            0.878608            0.838506   \n",
       "f1_score_class_0                          0.646985            0.649587   \n",
       "f1_score_class_1                          0.854757            0.842346   \n",
       "sample_class_0                           71.800000           71.800000   \n",
       "sample_class_1                          159.800000          159.800000   \n",
       "\n",
       "                    dehatebert-mono-german  distilbert-base-german-cased  \\\n",
       "Metrics                                                                    \n",
       "acc                               0.677045                      0.776347   \n",
       "bal_acc                           0.575248                      0.732023   \n",
       "mcc                               0.149182                      0.472484   \n",
       "f1_macro                          0.535920                      0.733969   \n",
       "f1_micro                          0.677045                      0.776347   \n",
       "f1_weighted                       0.628200                      0.774022   \n",
       "precision_macro                   0.512370                      0.740973   \n",
       "precision_micro                   0.677045                      0.776347   \n",
       "precision_weighted                0.598688                      0.775585   \n",
       "recall_macro                      0.575248                      0.732023   \n",
       "recall_micro                      0.677045                      0.776347   \n",
       "recall_weighted                   0.677045                      0.776347   \n",
       "precision_class_0                 0.285683                      0.649726   \n",
       "precision_class_1                 0.739057                      0.832220   \n",
       "recall_class_0                    0.308333                      0.615571   \n",
       "recall_class_1                    0.842162                      0.848475   \n",
       "f1_score_class_0                  0.293761                      0.628579   \n",
       "f1_score_class_1                  0.778080                      0.839359   \n",
       "sample_class_0                   71.800000                     71.800000   \n",
       "sample_class_1                  159.800000                    159.800000   \n",
       "\n",
       "                    gbert-hasoc-2019  electra-german-uncased  \\\n",
       "Metrics                                                        \n",
       "acc                         0.782341                0.809169   \n",
       "bal_acc                     0.717156                0.764376   \n",
       "mcc                         0.466152                0.544674   \n",
       "f1_macro                    0.728257                0.770875   \n",
       "f1_micro                    0.782341                0.809169   \n",
       "f1_weighted                 0.774304                0.806420   \n",
       "precision_macro             0.750372                0.780680   \n",
       "precision_micro             0.782341                0.809169   \n",
       "precision_weighted          0.774474                0.806169   \n",
       "recall_macro                0.717156                0.764376   \n",
       "recall_micro                0.782341                0.809169   \n",
       "recall_weighted             0.782341                0.809169   \n",
       "precision_class_0           0.687026                0.713744   \n",
       "precision_class_1           0.813719                0.847615   \n",
       "recall_class_0              0.545696                0.646362   \n",
       "recall_class_1              0.888616                0.882390   \n",
       "f1_score_class_0            0.607160                0.677333   \n",
       "f1_score_class_1            0.849354                0.864417   \n",
       "sample_class_0             71.800000               71.800000   \n",
       "sample_class_1            159.800000              159.800000   \n",
       "\n",
       "                    xlm-roberta-base  cardiff-xlm-roberta-base  \\\n",
       "Metrics                                                          \n",
       "acc                         0.773716                  0.768562   \n",
       "bal_acc                     0.739326                  0.701237   \n",
       "mcc                         0.475272                  0.437749   \n",
       "f1_macro                    0.736971                  0.710270   \n",
       "f1_micro                    0.773716                  0.768562   \n",
       "f1_weighted                 0.774242                  0.759250   \n",
       "precision_macro             0.736056                  0.739660   \n",
       "precision_micro             0.773716                  0.768562   \n",
       "precision_weighted          0.775912                  0.764734   \n",
       "recall_macro                0.739326                  0.701237   \n",
       "recall_micro                0.773716                  0.768562   \n",
       "recall_weighted             0.773716                  0.768562   \n",
       "precision_class_0           0.631143                  0.673909   \n",
       "precision_class_1           0.840968                  0.805410   \n",
       "recall_class_0              0.648905                  0.523787   \n",
       "recall_class_1              0.829748                  0.878687   \n",
       "f1_score_class_0            0.638915                  0.581307   \n",
       "f1_score_class_1            0.835028                  0.839233   \n",
       "sample_class_0             71.800000                 71.800000   \n",
       "sample_class_1            159.800000                159.800000   \n",
       "\n",
       "                    xlm-roberta-t-systems  german-toxicity-classifier  \n",
       "Metrics                                                                \n",
       "acc                              0.789271                    0.805684  \n",
       "bal_acc                          0.731358                    0.760148  \n",
       "mcc                              0.488437                    0.536026  \n",
       "f1_macro                         0.740094                    0.766381  \n",
       "f1_micro                         0.789271                    0.805684  \n",
       "f1_weighted                      0.782932                    0.802734  \n",
       "precision_macro                  0.758342                    0.776310  \n",
       "precision_micro                  0.789271                    0.805684  \n",
       "precision_weighted               0.783621                    0.802567  \n",
       "recall_macro                     0.731358                    0.760148  \n",
       "recall_micro                     0.789271                    0.805684  \n",
       "recall_weighted                  0.789271                    0.805684  \n",
       "precision_class_0                0.691855                    0.707172  \n",
       "precision_class_1                0.824828                    0.845449  \n",
       "recall_class_0                   0.579069                    0.640493  \n",
       "recall_class_1                   0.883648                    0.879803  \n",
       "f1_score_class_0                 0.627441                    0.670784  \n",
       "f1_score_class_1                 0.852747                    0.861977  \n",
       "sample_class_0                  71.800000                   71.800000  \n",
       "sample_class_1                 159.800000                  159.800000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = bert_base_german_cased[\"Metrics\"].tolist()\n",
    "df = pd.DataFrame()\n",
    "df[\"Metrics\"] = metrics\n",
    "df[\"bert-base-german-cased\"] = bert_base_german_cased[\"Overall Results\"]\n",
    "df[\"bert-base-multilingual-cased\"] = bert_base_multi_cased[\"Overall Results\"]\n",
    "df[\"bert-base-multilingual-uncased\"] = bert_base_multi_uncased[\"Overall Results\"]\n",
    "df[\"dbmdz-bert-base-german-cased\"] = dbmdz_bert_base_german_cased[\"Overall Results\"]\n",
    "df[\"dbmdz-bert-base-german-uncased\"] = dbmdz_bert_base_german_uncased[\"Overall Results\"]\n",
    "df[\"deepset-gbert-base\"] = deepset_gbert_base[\"Overall Results\"]\n",
    "df[\"dehatebert-mono-german\"] = dehatebert_mono_german[\"Overall Results\"]\n",
    "df[\"distilbert-base-german-cased\"] = distilbert_base_german_cased[\"Overall Results\"]\n",
    "df[\"gbert-hasoc-2019\"] = gbert_hasoc_2019[\"Overall Results\"]\n",
    "df[\"electra-german-uncased\"] = electra_german_uncased[\"Overall Results\"]\n",
    "df[\"xlm-roberta-base\"] = xlm_roberta_base[\"Overall Results\"]\n",
    "df[\"cardiff-xlm-roberta-base\"] = cardiff_xlm_roberta[\"Overall Results\"]\n",
    "df[\"xlm-roberta-t-systems\"] = roberta_t_systems[\"Overall Results\"]\n",
    "df[\"german-toxicity-classifier\"] = german_toxicity[\"Overall Results\"]\n",
    "df = df.set_index(\"Metrics\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e9441dd-5f3f-4940-b1aa-9b5c05671d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = [0.7323145245559038, 'NA', 'NA', 0.6318707895748974, 0.7323145245559038,0.704934938056964,\n",
    "      0.6895210843213938,0.7323145245559038,0.7140149807626603,0.6241947729353058,0.7323145245559038, 0.7140149807626603,'NA',\n",
    "      'NA','NA','NA','NA','NA', 71.8, 159.8]\n",
    "df[\"SVM\"] = svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21f74bce-8091-4a34-99db-a8cea91dd9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = pd.read_csv(\"LSTM_overall.csv\")\n",
    "lstm_l = lstm[\"Overall Results\"].tolist()\n",
    "df[\"LSTM Model\"] = lstm_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5658414-9418-43c0-ba00-1b14d90e1c64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>acc</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>precision_class_0</th>\n",
       "      <th>precision_class_1</th>\n",
       "      <th>recall_class_0</th>\n",
       "      <th>recall_class_1</th>\n",
       "      <th>f1_score_class_0</th>\n",
       "      <th>f1_score_class_1</th>\n",
       "      <th>sample_class_0</th>\n",
       "      <th>sample_class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>electra-german-uncased</th>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.764376</td>\n",
       "      <td>0.544674</td>\n",
       "      <td>0.770875</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.80642</td>\n",
       "      <td>0.78068</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.806169</td>\n",
       "      <td>0.764376</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.809169</td>\n",
       "      <td>0.713744</td>\n",
       "      <td>0.847615</td>\n",
       "      <td>0.646362</td>\n",
       "      <td>0.88239</td>\n",
       "      <td>0.677333</td>\n",
       "      <td>0.864417</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german-toxicity-classifier</th>\n",
       "      <td>0.805684</td>\n",
       "      <td>0.760148</td>\n",
       "      <td>0.536026</td>\n",
       "      <td>0.766381</td>\n",
       "      <td>0.805684</td>\n",
       "      <td>0.802734</td>\n",
       "      <td>0.77631</td>\n",
       "      <td>0.805684</td>\n",
       "      <td>0.802567</td>\n",
       "      <td>0.760148</td>\n",
       "      <td>0.805684</td>\n",
       "      <td>0.805684</td>\n",
       "      <td>0.707172</td>\n",
       "      <td>0.845449</td>\n",
       "      <td>0.640493</td>\n",
       "      <td>0.879803</td>\n",
       "      <td>0.670784</td>\n",
       "      <td>0.861977</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbmdz-bert-base-german-uncased</th>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.742982</td>\n",
       "      <td>0.507324</td>\n",
       "      <td>0.750871</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.79034</td>\n",
       "      <td>0.765142</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.790998</td>\n",
       "      <td>0.742982</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.794451</td>\n",
       "      <td>0.697255</td>\n",
       "      <td>0.833028</td>\n",
       "      <td>0.607355</td>\n",
       "      <td>0.878608</td>\n",
       "      <td>0.646985</td>\n",
       "      <td>0.854757</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-t-systems</th>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.731358</td>\n",
       "      <td>0.488437</td>\n",
       "      <td>0.740094</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.782932</td>\n",
       "      <td>0.758342</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.783621</td>\n",
       "      <td>0.731358</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.789271</td>\n",
       "      <td>0.691855</td>\n",
       "      <td>0.824828</td>\n",
       "      <td>0.579069</td>\n",
       "      <td>0.883648</td>\n",
       "      <td>0.627441</td>\n",
       "      <td>0.852747</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepset-gbert-base</th>\n",
       "      <td>0.78324</td>\n",
       "      <td>0.749417</td>\n",
       "      <td>0.496862</td>\n",
       "      <td>0.745967</td>\n",
       "      <td>0.78324</td>\n",
       "      <td>0.782577</td>\n",
       "      <td>0.74805</td>\n",
       "      <td>0.78324</td>\n",
       "      <td>0.78612</td>\n",
       "      <td>0.749417</td>\n",
       "      <td>0.78324</td>\n",
       "      <td>0.78324</td>\n",
       "      <td>0.647879</td>\n",
       "      <td>0.848221</td>\n",
       "      <td>0.660329</td>\n",
       "      <td>0.838506</td>\n",
       "      <td>0.649587</td>\n",
       "      <td>0.842346</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbert-hasoc-2019</th>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.717156</td>\n",
       "      <td>0.466152</td>\n",
       "      <td>0.728257</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.774304</td>\n",
       "      <td>0.750372</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.774474</td>\n",
       "      <td>0.717156</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.782341</td>\n",
       "      <td>0.687026</td>\n",
       "      <td>0.813719</td>\n",
       "      <td>0.545696</td>\n",
       "      <td>0.888616</td>\n",
       "      <td>0.60716</td>\n",
       "      <td>0.849354</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-base</th>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>0.475272</td>\n",
       "      <td>0.736971</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.774242</td>\n",
       "      <td>0.736056</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.775912</td>\n",
       "      <td>0.739326</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.773716</td>\n",
       "      <td>0.631143</td>\n",
       "      <td>0.840968</td>\n",
       "      <td>0.648905</td>\n",
       "      <td>0.829748</td>\n",
       "      <td>0.638915</td>\n",
       "      <td>0.835028</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distilbert-base-german-cased</th>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.732023</td>\n",
       "      <td>0.472484</td>\n",
       "      <td>0.733969</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.774022</td>\n",
       "      <td>0.740973</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.775585</td>\n",
       "      <td>0.732023</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.776347</td>\n",
       "      <td>0.649726</td>\n",
       "      <td>0.83222</td>\n",
       "      <td>0.615571</td>\n",
       "      <td>0.848475</td>\n",
       "      <td>0.628579</td>\n",
       "      <td>0.839359</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-german-cased</th>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.73244</td>\n",
       "      <td>0.470449</td>\n",
       "      <td>0.732925</td>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.772278</td>\n",
       "      <td>0.738523</td>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.774727</td>\n",
       "      <td>0.73244</td>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.773761</td>\n",
       "      <td>0.64308</td>\n",
       "      <td>0.833966</td>\n",
       "      <td>0.623905</td>\n",
       "      <td>0.840975</td>\n",
       "      <td>0.629384</td>\n",
       "      <td>0.836466</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbmdz-bert-base-german-cased</th>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.717984</td>\n",
       "      <td>0.457526</td>\n",
       "      <td>0.72423</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.770235</td>\n",
       "      <td>0.740767</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.770149</td>\n",
       "      <td>0.717984</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.778012</td>\n",
       "      <td>0.663425</td>\n",
       "      <td>0.818108</td>\n",
       "      <td>0.559859</td>\n",
       "      <td>0.876108</td>\n",
       "      <td>0.603058</td>\n",
       "      <td>0.845401</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cardiff-xlm-roberta-base</th>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.701237</td>\n",
       "      <td>0.437749</td>\n",
       "      <td>0.71027</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.75925</td>\n",
       "      <td>0.73966</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.764734</td>\n",
       "      <td>0.701237</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.768562</td>\n",
       "      <td>0.673909</td>\n",
       "      <td>0.80541</td>\n",
       "      <td>0.523787</td>\n",
       "      <td>0.878687</td>\n",
       "      <td>0.581307</td>\n",
       "      <td>0.839233</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-uncased</th>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.678968</td>\n",
       "      <td>0.378135</td>\n",
       "      <td>0.682305</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.734648</td>\n",
       "      <td>0.700926</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.737279</td>\n",
       "      <td>0.678968</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.743492</td>\n",
       "      <td>0.605176</td>\n",
       "      <td>0.796676</td>\n",
       "      <td>0.509351</td>\n",
       "      <td>0.848585</td>\n",
       "      <td>0.544632</td>\n",
       "      <td>0.819979</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bert-base-multilingual-cased</th>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.688873</td>\n",
       "      <td>0.36792</td>\n",
       "      <td>0.676904</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.719286</td>\n",
       "      <td>0.679715</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.73336</td>\n",
       "      <td>0.688873</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.717641</td>\n",
       "      <td>0.538564</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>0.61295</td>\n",
       "      <td>0.764796</td>\n",
       "      <td>0.565271</td>\n",
       "      <td>0.788537</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM</th>\n",
       "      <td>0.732315</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>0.631871</td>\n",
       "      <td>0.732315</td>\n",
       "      <td>0.704935</td>\n",
       "      <td>0.689521</td>\n",
       "      <td>0.732315</td>\n",
       "      <td>0.714015</td>\n",
       "      <td>0.624195</td>\n",
       "      <td>0.732315</td>\n",
       "      <td>0.714015</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM Model</th>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.592989</td>\n",
       "      <td>0.211767</td>\n",
       "      <td>0.595506</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.667165</td>\n",
       "      <td>0.621415</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.667002</td>\n",
       "      <td>0.592989</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.684796</td>\n",
       "      <td>0.501559</td>\n",
       "      <td>0.74127</td>\n",
       "      <td>0.351135</td>\n",
       "      <td>0.834843</td>\n",
       "      <td>0.406829</td>\n",
       "      <td>0.784182</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dehatebert-mono-german</th>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.575248</td>\n",
       "      <td>0.149182</td>\n",
       "      <td>0.53592</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.6282</td>\n",
       "      <td>0.51237</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.598688</td>\n",
       "      <td>0.575248</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.677045</td>\n",
       "      <td>0.285683</td>\n",
       "      <td>0.739057</td>\n",
       "      <td>0.308333</td>\n",
       "      <td>0.842162</td>\n",
       "      <td>0.293761</td>\n",
       "      <td>0.77808</td>\n",
       "      <td>71.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              acc   bal_acc       mcc  f1_macro  \\\n",
       "electra-german-uncased          0.809169  0.764376  0.544674  0.770875   \n",
       "german-toxicity-classifier      0.805684  0.760148  0.536026  0.766381   \n",
       "dbmdz-bert-base-german-uncased  0.794451  0.742982  0.507324  0.750871   \n",
       "xlm-roberta-t-systems           0.789271  0.731358  0.488437  0.740094   \n",
       "deepset-gbert-base               0.78324  0.749417  0.496862  0.745967   \n",
       "gbert-hasoc-2019                0.782341  0.717156  0.466152  0.728257   \n",
       "xlm-roberta-base                0.773716  0.739326  0.475272  0.736971   \n",
       "distilbert-base-german-cased    0.776347  0.732023  0.472484  0.733969   \n",
       "bert-base-german-cased          0.773761   0.73244  0.470449  0.732925   \n",
       "dbmdz-bert-base-german-cased    0.778012  0.717984  0.457526   0.72423   \n",
       "cardiff-xlm-roberta-base        0.768562  0.701237  0.437749   0.71027   \n",
       "bert-base-multilingual-uncased  0.743492  0.678968  0.378135  0.682305   \n",
       "bert-base-multilingual-cased    0.717641  0.688873   0.36792  0.676904   \n",
       "SVM                             0.732315        NA        NA  0.631871   \n",
       "LSTM Model                      0.684796  0.592989  0.211767  0.595506   \n",
       "dehatebert-mono-german          0.677045  0.575248  0.149182   0.53592   \n",
       "\n",
       "Metrics                         f1_micro f1_weighted precision_macro  \\\n",
       "electra-german-uncased          0.809169     0.80642         0.78068   \n",
       "german-toxicity-classifier      0.805684    0.802734         0.77631   \n",
       "dbmdz-bert-base-german-uncased  0.794451     0.79034        0.765142   \n",
       "xlm-roberta-t-systems           0.789271    0.782932        0.758342   \n",
       "deepset-gbert-base               0.78324    0.782577         0.74805   \n",
       "gbert-hasoc-2019                0.782341    0.774304        0.750372   \n",
       "xlm-roberta-base                0.773716    0.774242        0.736056   \n",
       "distilbert-base-german-cased    0.776347    0.774022        0.740973   \n",
       "bert-base-german-cased          0.773761    0.772278        0.738523   \n",
       "dbmdz-bert-base-german-cased    0.778012    0.770235        0.740767   \n",
       "cardiff-xlm-roberta-base        0.768562     0.75925         0.73966   \n",
       "bert-base-multilingual-uncased  0.743492    0.734648        0.700926   \n",
       "bert-base-multilingual-cased    0.717641    0.719286        0.679715   \n",
       "SVM                             0.732315    0.704935        0.689521   \n",
       "LSTM Model                      0.684796    0.667165        0.621415   \n",
       "dehatebert-mono-german          0.677045      0.6282         0.51237   \n",
       "\n",
       "Metrics                        precision_micro precision_weighted  \\\n",
       "electra-german-uncased                0.809169           0.806169   \n",
       "german-toxicity-classifier            0.805684           0.802567   \n",
       "dbmdz-bert-base-german-uncased        0.794451           0.790998   \n",
       "xlm-roberta-t-systems                 0.789271           0.783621   \n",
       "deepset-gbert-base                     0.78324            0.78612   \n",
       "gbert-hasoc-2019                      0.782341           0.774474   \n",
       "xlm-roberta-base                      0.773716           0.775912   \n",
       "distilbert-base-german-cased          0.776347           0.775585   \n",
       "bert-base-german-cased                0.773761           0.774727   \n",
       "dbmdz-bert-base-german-cased          0.778012           0.770149   \n",
       "cardiff-xlm-roberta-base              0.768562           0.764734   \n",
       "bert-base-multilingual-uncased        0.743492           0.737279   \n",
       "bert-base-multilingual-cased          0.717641            0.73336   \n",
       "SVM                                   0.732315           0.714015   \n",
       "LSTM Model                            0.684796           0.667002   \n",
       "dehatebert-mono-german                0.677045           0.598688   \n",
       "\n",
       "Metrics                        recall_macro recall_micro recall_weighted  \\\n",
       "electra-german-uncased             0.764376     0.809169        0.809169   \n",
       "german-toxicity-classifier         0.760148     0.805684        0.805684   \n",
       "dbmdz-bert-base-german-uncased     0.742982     0.794451        0.794451   \n",
       "xlm-roberta-t-systems              0.731358     0.789271        0.789271   \n",
       "deepset-gbert-base                 0.749417      0.78324         0.78324   \n",
       "gbert-hasoc-2019                   0.717156     0.782341        0.782341   \n",
       "xlm-roberta-base                   0.739326     0.773716        0.773716   \n",
       "distilbert-base-german-cased       0.732023     0.776347        0.776347   \n",
       "bert-base-german-cased              0.73244     0.773761        0.773761   \n",
       "dbmdz-bert-base-german-cased       0.717984     0.778012        0.778012   \n",
       "cardiff-xlm-roberta-base           0.701237     0.768562        0.768562   \n",
       "bert-base-multilingual-uncased     0.678968     0.743492        0.743492   \n",
       "bert-base-multilingual-cased       0.688873     0.717641        0.717641   \n",
       "SVM                                0.624195     0.732315        0.714015   \n",
       "LSTM Model                         0.592989     0.684796        0.684796   \n",
       "dehatebert-mono-german             0.575248     0.677045        0.677045   \n",
       "\n",
       "Metrics                        precision_class_0 precision_class_1  \\\n",
       "electra-german-uncased                  0.713744          0.847615   \n",
       "german-toxicity-classifier              0.707172          0.845449   \n",
       "dbmdz-bert-base-german-uncased          0.697255          0.833028   \n",
       "xlm-roberta-t-systems                   0.691855          0.824828   \n",
       "deepset-gbert-base                      0.647879          0.848221   \n",
       "gbert-hasoc-2019                        0.687026          0.813719   \n",
       "xlm-roberta-base                        0.631143          0.840968   \n",
       "distilbert-base-german-cased            0.649726           0.83222   \n",
       "bert-base-german-cased                   0.64308          0.833966   \n",
       "dbmdz-bert-base-german-cased            0.663425          0.818108   \n",
       "cardiff-xlm-roberta-base                0.673909           0.80541   \n",
       "bert-base-multilingual-uncased          0.605176          0.796676   \n",
       "bert-base-multilingual-cased            0.538564          0.820865   \n",
       "SVM                                           NA                NA   \n",
       "LSTM Model                              0.501559           0.74127   \n",
       "dehatebert-mono-german                  0.285683          0.739057   \n",
       "\n",
       "Metrics                        recall_class_0 recall_class_1 f1_score_class_0  \\\n",
       "electra-german-uncased               0.646362        0.88239         0.677333   \n",
       "german-toxicity-classifier           0.640493       0.879803         0.670784   \n",
       "dbmdz-bert-base-german-uncased       0.607355       0.878608         0.646985   \n",
       "xlm-roberta-t-systems                0.579069       0.883648         0.627441   \n",
       "deepset-gbert-base                   0.660329       0.838506         0.649587   \n",
       "gbert-hasoc-2019                     0.545696       0.888616          0.60716   \n",
       "xlm-roberta-base                     0.648905       0.829748         0.638915   \n",
       "distilbert-base-german-cased         0.615571       0.848475         0.628579   \n",
       "bert-base-german-cased               0.623905       0.840975         0.629384   \n",
       "dbmdz-bert-base-german-cased         0.559859       0.876108         0.603058   \n",
       "cardiff-xlm-roberta-base             0.523787       0.878687         0.581307   \n",
       "bert-base-multilingual-uncased       0.509351       0.848585         0.544632   \n",
       "bert-base-multilingual-cased          0.61295       0.764796         0.565271   \n",
       "SVM                                        NA             NA               NA   \n",
       "LSTM Model                           0.351135       0.834843         0.406829   \n",
       "dehatebert-mono-german               0.308333       0.842162         0.293761   \n",
       "\n",
       "Metrics                        f1_score_class_1 sample_class_0 sample_class_1  \n",
       "electra-german-uncased                 0.864417           71.8          159.8  \n",
       "german-toxicity-classifier             0.861977           71.8          159.8  \n",
       "dbmdz-bert-base-german-uncased         0.854757           71.8          159.8  \n",
       "xlm-roberta-t-systems                  0.852747           71.8          159.8  \n",
       "deepset-gbert-base                     0.842346           71.8          159.8  \n",
       "gbert-hasoc-2019                       0.849354           71.8          159.8  \n",
       "xlm-roberta-base                       0.835028           71.8          159.8  \n",
       "distilbert-base-german-cased           0.839359           71.8          159.8  \n",
       "bert-base-german-cased                 0.836466           71.8          159.8  \n",
       "dbmdz-bert-base-german-cased           0.845401           71.8          159.8  \n",
       "cardiff-xlm-roberta-base               0.839233           71.8          159.8  \n",
       "bert-base-multilingual-uncased         0.819979           71.8          159.8  \n",
       "bert-base-multilingual-cased           0.788537           71.8          159.8  \n",
       "SVM                                          NA           71.8          159.8  \n",
       "LSTM Model                             0.784182           71.8          159.8  \n",
       "dehatebert-mono-german                  0.77808           71.8          159.8  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.T\n",
    "df = df.sort_values(by=[\"f1_weighted\"], ascending=False)\n",
    "df.to_csv(\"Model_Results_Overview.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5efebc93-29a3-4cb6-a9cc-b5884e852132",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Balanced Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f83a26f1-6384-4058-bb68-f1abc615a30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "bert_dbmdz_uncased = pd.read_csv(\"../KFOLD_Balanced_Model_Results/BALANCED_bert_dbmdz_uncased.csv\")\n",
    "gbert_base = pd.read_csv(\"../KFOLD_Balanced_Model_Results/BALANCED_deepset_gbert_base.csv\")\n",
    "electra_uncased = pd.read_csv(\"../KFOLD_Balanced_Model_Results/BALANCED_electra_base_german_uncased.csv\")\n",
    "german_toxicity = pd.read_csv(\"../KFOLD_Balanced_Model_Results/BALANCED_german_toxicity.csv\")\n",
    "xlm = pd.read_csv(\"../KFOLD_Balanced_Model_Results/BALANCED_xlm-roberta-t-systems.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54a4014c-41f2-4cfe-8b9a-da941742e50e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Metrics</th>\n",
       "      <th>acc</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_weighted</th>\n",
       "      <th>precision_class_0</th>\n",
       "      <th>precision_class_1</th>\n",
       "      <th>recall_class_0</th>\n",
       "      <th>recall_class_1</th>\n",
       "      <th>f1_score_class_0</th>\n",
       "      <th>f1_score_class_1</th>\n",
       "      <th>sample_class_0</th>\n",
       "      <th>sample_class_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>electra-german-uncased</th>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.846108</td>\n",
       "      <td>0.693754</td>\n",
       "      <td>0.845936</td>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.845933</td>\n",
       "      <td>0.847649</td>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.847671</td>\n",
       "      <td>0.846108</td>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.846082</td>\n",
       "      <td>0.865610</td>\n",
       "      <td>0.829688</td>\n",
       "      <td>0.821053</td>\n",
       "      <td>0.871164</td>\n",
       "      <td>0.842308</td>\n",
       "      <td>0.849564</td>\n",
       "      <td>159.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deepset-gbert-base</th>\n",
       "      <td>0.844195</td>\n",
       "      <td>0.844198</td>\n",
       "      <td>0.689263</td>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.844195</td>\n",
       "      <td>0.844079</td>\n",
       "      <td>0.845067</td>\n",
       "      <td>0.844195</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.844198</td>\n",
       "      <td>0.844195</td>\n",
       "      <td>0.844195</td>\n",
       "      <td>0.851210</td>\n",
       "      <td>0.838923</td>\n",
       "      <td>0.834803</td>\n",
       "      <td>0.853593</td>\n",
       "      <td>0.842429</td>\n",
       "      <td>0.845729</td>\n",
       "      <td>159.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>german-toxicity-classifier</th>\n",
       "      <td>0.843556</td>\n",
       "      <td>0.843542</td>\n",
       "      <td>0.688923</td>\n",
       "      <td>0.843347</td>\n",
       "      <td>0.843556</td>\n",
       "      <td>0.843350</td>\n",
       "      <td>0.845385</td>\n",
       "      <td>0.843556</td>\n",
       "      <td>0.845377</td>\n",
       "      <td>0.843542</td>\n",
       "      <td>0.843556</td>\n",
       "      <td>0.843556</td>\n",
       "      <td>0.868774</td>\n",
       "      <td>0.821997</td>\n",
       "      <td>0.809741</td>\n",
       "      <td>0.877343</td>\n",
       "      <td>0.838054</td>\n",
       "      <td>0.848641</td>\n",
       "      <td>159.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xlm-roberta-t-systems</th>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.827956</td>\n",
       "      <td>0.656941</td>\n",
       "      <td>0.827793</td>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.827789</td>\n",
       "      <td>0.828986</td>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.829007</td>\n",
       "      <td>0.827956</td>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.827927</td>\n",
       "      <td>0.835108</td>\n",
       "      <td>0.822865</td>\n",
       "      <td>0.819835</td>\n",
       "      <td>0.836077</td>\n",
       "      <td>0.826778</td>\n",
       "      <td>0.828808</td>\n",
       "      <td>159.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dbmdz-bert-base-german-uncased</th>\n",
       "      <td>0.773348</td>\n",
       "      <td>0.773054</td>\n",
       "      <td>0.546951</td>\n",
       "      <td>0.739725</td>\n",
       "      <td>0.773348</td>\n",
       "      <td>0.739932</td>\n",
       "      <td>0.724055</td>\n",
       "      <td>0.773348</td>\n",
       "      <td>0.724227</td>\n",
       "      <td>0.773054</td>\n",
       "      <td>0.773348</td>\n",
       "      <td>0.773348</td>\n",
       "      <td>0.681590</td>\n",
       "      <td>0.766520</td>\n",
       "      <td>0.661250</td>\n",
       "      <td>0.884858</td>\n",
       "      <td>0.670825</td>\n",
       "      <td>0.808624</td>\n",
       "      <td>159.8</td>\n",
       "      <td>159.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Metrics                              acc   bal_acc       mcc  f1_macro  \\\n",
       "electra-german-uncased          0.846082  0.846108  0.693754  0.845936   \n",
       "deepset-gbert-base              0.844195  0.844198  0.689263  0.844079   \n",
       "german-toxicity-classifier      0.843556  0.843542  0.688923  0.843347   \n",
       "xlm-roberta-t-systems           0.827927  0.827956  0.656941  0.827793   \n",
       "dbmdz-bert-base-german-uncased  0.773348  0.773054  0.546951  0.739725   \n",
       "\n",
       "Metrics                         f1_micro  f1_weighted  precision_macro  \\\n",
       "electra-german-uncased          0.846082     0.845933         0.847649   \n",
       "deepset-gbert-base              0.844195     0.844079         0.845067   \n",
       "german-toxicity-classifier      0.843556     0.843350         0.845385   \n",
       "xlm-roberta-t-systems           0.827927     0.827789         0.828986   \n",
       "dbmdz-bert-base-german-uncased  0.773348     0.739932         0.724055   \n",
       "\n",
       "Metrics                         precision_micro  precision_weighted  \\\n",
       "electra-german-uncased                 0.846082            0.847671   \n",
       "deepset-gbert-base                     0.844195            0.845070   \n",
       "german-toxicity-classifier             0.843556            0.845377   \n",
       "xlm-roberta-t-systems                  0.827927            0.829007   \n",
       "dbmdz-bert-base-german-uncased         0.773348            0.724227   \n",
       "\n",
       "Metrics                         recall_macro  recall_micro  recall_weighted  \\\n",
       "electra-german-uncased              0.846108      0.846082         0.846082   \n",
       "deepset-gbert-base                  0.844198      0.844195         0.844195   \n",
       "german-toxicity-classifier          0.843542      0.843556         0.843556   \n",
       "xlm-roberta-t-systems               0.827956      0.827927         0.827927   \n",
       "dbmdz-bert-base-german-uncased      0.773054      0.773348         0.773348   \n",
       "\n",
       "Metrics                         precision_class_0  precision_class_1  \\\n",
       "electra-german-uncased                   0.865610           0.829688   \n",
       "deepset-gbert-base                       0.851210           0.838923   \n",
       "german-toxicity-classifier               0.868774           0.821997   \n",
       "xlm-roberta-t-systems                    0.835108           0.822865   \n",
       "dbmdz-bert-base-german-uncased           0.681590           0.766520   \n",
       "\n",
       "Metrics                         recall_class_0  recall_class_1  \\\n",
       "electra-german-uncased                0.821053        0.871164   \n",
       "deepset-gbert-base                    0.834803        0.853593   \n",
       "german-toxicity-classifier            0.809741        0.877343   \n",
       "xlm-roberta-t-systems                 0.819835        0.836077   \n",
       "dbmdz-bert-base-german-uncased        0.661250        0.884858   \n",
       "\n",
       "Metrics                         f1_score_class_0  f1_score_class_1  \\\n",
       "electra-german-uncased                  0.842308          0.849564   \n",
       "deepset-gbert-base                      0.842429          0.845729   \n",
       "german-toxicity-classifier              0.838054          0.848641   \n",
       "xlm-roberta-t-systems                   0.826778          0.828808   \n",
       "dbmdz-bert-base-german-uncased          0.670825          0.808624   \n",
       "\n",
       "Metrics                         sample_class_0  sample_class_1  \n",
       "electra-german-uncased                   159.8           159.8  \n",
       "deepset-gbert-base                       159.8           159.8  \n",
       "german-toxicity-classifier               159.8           159.8  \n",
       "xlm-roberta-t-systems                    159.8           159.8  \n",
       "dbmdz-bert-base-german-uncased           159.8           159.8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = bert_dbmdz_uncased[\"Metrics\"].tolist()\n",
    "df = pd.DataFrame()\n",
    "df[\"Metrics\"] = metrics\n",
    "df[\"dbmdz-bert-base-german-uncased\"] = bert_dbmdz_uncased[\"Overall Results\"]\n",
    "df[\"deepset-gbert-base\"] = gbert_base[\"Overall Results\"]\n",
    "df[\"electra-german-uncased\"] = electra_uncased[\"Overall Results\"]\n",
    "df[\"german-toxicity-classifier\"] = german_toxicity[\"Overall Results\"]\n",
    "df[\"xlm-roberta-t-systems\"] = xlm[\"Overall Results\"]\n",
    "df = df.set_index(\"Metrics\")\n",
    "df = df.T\n",
    "df = df.sort_values(by=[\"f1_weighted\"], ascending=False)\n",
    "df.to_csv(\"../KFOLD_Balanced_Model_Results/Balanced_Model_Results_Overview.csv\")\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
