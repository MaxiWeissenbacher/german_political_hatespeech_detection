{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c61e0b91-b389-4f08-8e06-9f59f0b8a8d8",
   "metadata": {},
   "source": [
    "# Ensemble Approach"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c677d187-c663-4eee-b005-4a366da2640c",
   "metadata": {},
   "source": [
    "Approach to build Ensemble Models with Hard- and Softvoting.\n",
    "The goal is to further improve the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f065419e-643a-4352-aa60-873f69c802da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torchvision\n",
    "!pip install wandb\n",
    "!pip install ipynb\n",
    "!pip install s3fs\n",
    "!pip install nvidia-ml-py3\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1bd19f6-7c65-4b16-b0e9-77db505f9484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from transformers import XLMRobertaTokenizer, XLMRobertaForSequenceClassification\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report \n",
    "from transformers import get_scheduler\n",
    "from transformers import AdamW\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import json\n",
    "import s3fs\n",
    "import os\n",
    "import torch\n",
    "from ipynb.fs.full.eval_metrics import *\n",
    "hello()\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# Opening JSON file\n",
    "with open('../credentials.json', 'r') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json_object = json.load(openfile)\n",
    "    key = json_object[\"key\"]\n",
    "    secret = json_object[\"secret_key\"]\n",
    "    bucket_name = json_object[\"bucket_name\"]\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=False,key=key,secret=secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd0f3028-346c-41c1-9efa-9dfdbdd65ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = \"Ensemble\"\n",
    "\n",
    "train_test_number = [5]\n",
    "\n",
    "train_file_name = \"train_plus_neutral_germeval.csv\"\n",
    "test_file_name = \"test_plus_neutral_germeval.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "62713d6c-37b6-4d52-b319-7e67c93aebc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Test Datsets from foler KFOLD1 to KFOLD5\n",
    "with s3.open(f\"{bucket_name}/KFOLD5/{train_file_name}\",'r') as file:\n",
    "    data = pd.read_csv(file)\n",
    "with s3.open(f\"{bucket_name}/KFOLD5/{test_file_name}\",'r') as file:\n",
    "    test_data = pd.read_csv(file)\n",
    "data = data[[\"Text\", \"majority_vote\"]]\n",
    "test_data = test_data[[\"Text\", \"majority_vote\"]]\n",
    "data.rename(columns={'Text': 'text', 'majority_vote': 'labels'}, inplace=True)\n",
    "test_data.rename(columns={'Text': 'text', 'majority_vote': 'labels'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ac97116-259f-4f56-91a0-4700d510c12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize different tokenizers  to check which ensembles perform best\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EIStakovskii/german_toxicity_classifier_plus_v2\")\n",
    "tokenizer1 = AutoTokenizer.from_pretrained(\"german-nlp-group/electra-base-german-uncased\")\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(\"deepset/gbert-base\")\n",
    "#tokenizer3 = AutoTokenizer.from_pretrained(\"T-Systems-onsite/cross-en-de-roberta-sentence-transformer\")\n",
    "#tokenizer4 = AutoTokenizer.from_pretrained(\"bert-base-german-dbmdz-uncased\")\n",
    "#tokenizer5 = AutoTokenizer.from_pretrained(\"shahrukhx01/gbert-hasoc-german-2019\")\n",
    "#tokenizer6 = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e4cea44c-c790-4217-ae45-eb566438407d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ab42458a-3b1c-4c71-aa6c-16459ac1fc8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file BEST_Model_Toxicity_Ensemble_best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"BEST_Model_Toxicity_Ensemble_best_model\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"neutral\",\n",
      "    \"1\": \"toxic\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"neutral\": 0,\n",
      "    \"toxic\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file BEST_Model_Toxicity_Ensemble_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BEST_Model_Toxicity_Ensemble_best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file BEST_Model_Electra_with_Germeval_training_run5_best_model/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"BEST_Model_Electra_with_Germeval_training_run5_best_model\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading weights file BEST_Model_Electra_with_Germeval_training_run5_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at BEST_Model_Electra_with_Germeval_training_run5_best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "loading configuration file BEST_Model_gbert_base_Ensemble_best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"BEST_Model_gbert_base_Ensemble_best_model\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file BEST_Model_gbert_base_Ensemble_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BEST_Model_gbert_base_Ensemble_best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 319\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 319\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 319\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ----- 3. Predict -----#\n",
    "# Load test data and tokenize it with the specific toeknizer\n",
    "X_test = list(test_data[\"text\"])\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized1 = tokenizer1(X_test, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized2 = tokenizer2(X_test, padding=True, truncation=True, max_length=512)\n",
    "#X_test_tokenized3 = tokenizer3(X_test, padding=True, truncation=True, max_length=512)\n",
    "#X_test_tokenized4 = tokenizer4(X_test, padding=True, truncation=True, max_length=512)\n",
    "#X_test_tokenized5 = tokenizer5(X_test, padding=True, truncation=True, max_length=512)\n",
    "#X_test_tokenized6 = tokenizer6(X_test, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Create torch dataset\n",
    "test_dataset = Dataset(X_test_tokenized)\n",
    "test_dataset1 = Dataset(X_test_tokenized1)\n",
    "test_dataset2 = Dataset(X_test_tokenized2)\n",
    "#test_dataset3 = Dataset(X_test_tokenized3)\n",
    "#test_dataset4 = Dataset(X_test_tokenized4)\n",
    "#test_dataset5 = Dataset(X_test_tokenized5)\n",
    "#test_dataset6 = Dataset(X_test_tokenized6)\n",
    "\n",
    "# Load trained models\n",
    "#model = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_Toxicity_Ensemble_best_model\", num_labels=2)\n",
    "# mit dem Toxicity F1 Macro von 0.9 aber duplikate checken. Dennoch fÃ¼r Germeval mÃ¶glich\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_Toxicity_Ensemble_best_model\", num_labels=2)\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_Electra_with_Germeval_training_run5_best_model\", num_labels=2)\n",
    "#model1 = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_Electra_best_model\", num_labels=2)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_gbert_base_Ensemble_best_model\", num_labels=2)\n",
    "#model3 = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_roberta_t_systems_Ensemble_best_model\", num_labels=2)\n",
    "#model4 = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_bert_dbmdz_Ensemble_best_model\", num_labels=2)\n",
    "#model5 = AutoModelForSequenceClassification.from_pretrained(f\"shahrukhx01/gbert-hasoc-german-2019\", num_labels=2)\n",
    "#model6 = AutoModelForSequenceClassification.from_pretrained(f\"xlm-roberta-base\", num_labels=2)\n",
    "\n",
    "# Define test trainer\n",
    "test_trainer = Trainer(model)\n",
    "test_trainer1 = Trainer(model1)\n",
    "test_trainer2 = Trainer(model2)\n",
    "#test_trainer3 = Trainer(model3)\n",
    "#test_trainer4 = Trainer(model4)\n",
    "#test_trainer5 = Trainer(model5)\n",
    "#test_trainer6 = Trainer(model6)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "raw_pred1, _1, _1 = test_trainer1.predict(test_dataset1)\n",
    "raw_pred2, _2, _2 = test_trainer2.predict(test_dataset2)\n",
    "#raw_pred3, _3, _3 = test_trainer3.predict(test_dataset3)\n",
    "#raw_pred4, _4, _4 = test_trainer4.predict(test_dataset4)\n",
    "#raw_pred5, _5, _5 = test_trainer5.predict(test_dataset5)\n",
    "#raw_pred6, _6, _6 = test_trainer6.predict(test_dataset6)\n",
    "\n",
    "# Preprocess raw predictions\n",
    "y_pred = np.argmax(raw_pred, axis=1)\n",
    "y_pred1 = np.argmax(raw_pred1, axis=1)\n",
    "y_pred2 = np.argmax(raw_pred2, axis=1)\n",
    "#y_pred3 = np.argmax(raw_pred3, axis=1)\n",
    "#y_pred4 = np.argmax(raw_pred4, axis=1)\n",
    "#y_pred5 = np.argmax(raw_pred5, axis=1)\n",
    "#y_pred6 = np.argmax(raw_pred6, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44ca98cb-d843-45b3-a16c-dd64046cd412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Numpy Arrays to be able to do Soft Voting\n",
    "sum_array = np.add(raw_pred, raw_pred1)\n",
    "sum_array = np.add(sum_array, raw_pred2)\n",
    "# Bei 5 Classifiern\n",
    "#sum_array = np.add(sum_array, raw_pred3)\n",
    "#sum_array = np.add(sum_array, raw_pred4)\n",
    "# bei 7 Classifiern\n",
    "#sum_array = np.add(sum_array, raw_pred5)\n",
    "#sum_array = np.add(sum_array, raw_pred6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87ff925b-cefe-4223-8953-7a805a869df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-3.0195549,  3.1257925],\n",
       "       [-3.0411592,  3.149917 ],\n",
       "       [-3.0277221,  3.0879445],\n",
       "       [-2.9622777,  3.049275 ],\n",
       "       [-3.0159812,  3.1268773]], dtype=float32)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Divide 1 by the number of classifiers\n",
    "multi = np.multiply(sum_array, 0.33)\n",
    "#multi = np.multiply(sum_array, 0.5)\n",
    "multi[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b702f14c-1422-4928-beb2-d96cb9eb2f01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Soft Voting\n",
    "y_pred_soft = np.argmax(multi, axis=1)\n",
    "y_pred_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1d0bfa15-08fd-43cc-adf4-edb6478e4d68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hard Voting\n",
    "y_pred_ens = []\n",
    "\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] + y_pred1[i] + y_pred2[i]  > 1 :\n",
    "        res = 1\n",
    "        y_pred_ens.append(res)\n",
    "    else:\n",
    "        res = 0\n",
    "        y_pred_ens.append(res)\n",
    "        \n",
    "y_pred_ens = np.array(y_pred_ens)\n",
    "y_pred_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15a15041-61bf-46d8-a6c3-b7641051dc4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             1\n",
      "0                             \n",
      "acc                   0.893417\n",
      "bal_acc               0.893455\n",
      "mcc                   0.787096\n",
      "f1_macro              0.893408\n",
      "f1_micro              0.893417\n",
      "f1_weighted           0.893404\n",
      "precision_macro       0.893641\n",
      "precision_micro       0.893417\n",
      "precision_weighted    0.893673\n",
      "recall_macro          0.893455\n",
      "recall_micro          0.893417\n",
      "recall_weighted       0.893417\n",
      "precision_class_0     0.903846\n",
      "precision_class_1     0.883436\n",
      "recall_class_0        0.881250\n",
      "recall_class_1        0.905660\n",
      "f1_score_class_0      0.892405\n",
      "f1_score_class_1      0.894410\n",
      "sample_class_0      160.000000\n",
      "sample_class_1      159.000000\n",
      "Finished Fold Number: Germeval\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare Hard Voting VS Soft Voting\n",
    "#y_pred = y_pred_ens\n",
    "y_pred = y_pred_soft\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "test_list = test_data[\"labels\"].tolist()\n",
    "test_list = np.array(test_list)\n",
    "\n",
    "    # Compute Evaluation Metrics\n",
    "f = f1_multiclass(test_list, y_pred)\n",
    "p = p_multiclass(test_list, y_pred)\n",
    "r = recall_multiclass(test_list, y_pred)\n",
    "a = accuracy_score(test_list, y_pred)\n",
    "ba = balanced_accuracy_score(test_list, y_pred)\n",
    "prs = precision_recall_fscore_support(test_list, y_pred)\n",
    "m = matthews_corrcoef(test_list,y_pred)\n",
    "\n",
    "results = {}\n",
    "results[\"acc\"] = a\n",
    "results[\"f1\"] = f\n",
    "results[\"precision\"] = p\n",
    "results[\"recall\"] = r\n",
    "results[\"bal_acc\"] = ba\n",
    "results[\"prfs\"] = prs\n",
    "results[\"mcc\"] = m\n",
    "\n",
    "prepare_results(results)\n",
    "result_df = dict_to_df(results)\n",
    "#result_df.to_csv(f\"Ensemble_3_results_hard_voting.csv\")\n",
    "print(result_df)\n",
    "class_rep = classification_report(test_list, y_pred,target_names=[\"HOF\", \"NOT\"])\n",
    "cm = confusion_matrix(test_list, y_pred,)\n",
    "ax = plt.subplot()\n",
    "cm_plot = sns.heatmap(cm, annot=True, fmt='g', ax=ax,cmap='Greens');\n",
    "# labels, title and ticks\n",
    "ax.set_xlabel('Predicted labels')\n",
    "ax.set_ylabel('True labels')\n",
    "ax.xaxis.set_ticklabels(['NOT', 'HOF'])\n",
    "ax.yaxis.set_ticklabels(['NOT', 'HOF']);\n",
    "cm_plot.figure.savefig(f\"./Ensemble_Results/Ensemble_Own_Data/CM_Ensemble_3_results_hard_voting.png\")\n",
    "print(f\"Finished Fold Number: Germeval\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f63cf910-d7c7-433f-bca4-d50f28ec9142",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Predict 1000 Random Tweets for the Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fa2d1f81-4a8c-4e8f-84f2-7d5d88677b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1094/2785248682.py:1: DtypeWarning: Columns (1,2,4,10,11) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(\"../full_datasets/all_mentions_data_combined_without_retweets.csv\")\n"
     ]
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"../full_datasets/all_mentions_data_combined_without_retweets.csv\")\n",
    "# Sample 1000 random tweets\n",
    "tweets = tweets.sample(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c3586c06-820b-4dac-b9c9-3b5ee0f7e5ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = tweets.text.dropna()\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5a311657-fbfc-4449-a032-f105197c6b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno = tweets[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d8cd29ec-d372-4059-8d03-6c870a7397f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1726998</th>\n",
       "      <td>@MichaelZimlich @GtzFrmming WÃ¤re auch fÃ¼r dies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193770</th>\n",
       "      <td>@cdljsjh2 @MarionaMarione @Karl_Lauterbach War...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686792</th>\n",
       "      <td>@Ralf_Stegner so sieht ein Speichellecker aus.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020273</th>\n",
       "      <td>@Sumoplay @Erwin_Rueddel @Karl_Lauterbach @CDU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028221</th>\n",
       "      <td>@Storch_i @maxmordhorst @DB_Bahn @DB_Presse @V...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979834</th>\n",
       "      <td>@n_roettgen Also ich Wagenknecht lad, habe ich...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390814</th>\n",
       "      <td>@DaldoDill @ninastahr @der_alex12 @gruene_juge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1158230</th>\n",
       "      <td>@MarwinZander @Karl_Lauterbach Mega joke.ðŸ˜‚  un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>717696</th>\n",
       "      <td>@realTomBohn @_MartinHagen @LindaTeuteberg @jo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1413031</th>\n",
       "      <td>@CLeiserfluss @Karl_Lauterbach Ich glaube sie ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text\n",
       "1726998  @MichaelZimlich @GtzFrmming WÃ¤re auch fÃ¼r dies...\n",
       "1193770  @cdljsjh2 @MarionaMarione @Karl_Lauterbach War...\n",
       "686792      @Ralf_Stegner so sieht ein Speichellecker aus.\n",
       "1020273  @Sumoplay @Erwin_Rueddel @Karl_Lauterbach @CDU...\n",
       "1028221  @Storch_i @maxmordhorst @DB_Bahn @DB_Presse @V...\n",
       "...                                                    ...\n",
       "979834   @n_roettgen Also ich Wagenknecht lad, habe ich...\n",
       "390814   @DaldoDill @ninastahr @der_alex12 @gruene_juge...\n",
       "1158230  @MarwinZander @Karl_Lauterbach Mega joke.ðŸ˜‚  un...\n",
       "717696   @realTomBohn @_MartinHagen @LindaTeuteberg @jo...\n",
       "1413031  @CLeiserfluss @Karl_Lauterbach Ich glaube sie ...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anno_df = pd.DataFrame()\n",
    "anno_df[\"text\"] = anno\n",
    "anno_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cce00798-8b17-40fc-8e2c-36ceed83c24d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file BEST_Model_Toxicity_Ensemble_best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"BEST_Model_Toxicity_Ensemble_best_model\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"neutral\",\n",
      "    \"1\": \"toxic\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"neutral\": 0,\n",
      "    \"toxic\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file BEST_Model_Toxicity_Ensemble_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BEST_Model_Toxicity_Ensemble_best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file BEST_Model_Electra_with_Germeval_training_run5_best_model/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"BEST_Model_Electra_with_Germeval_training_run5_best_model\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading weights file BEST_Model_Electra_with_Germeval_training_run5_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at BEST_Model_Electra_with_Germeval_training_run5_best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "loading configuration file BEST_Model_gbert_base_Ensemble_best_model/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"BEST_Model_gbert_base_Ensemble_best_model\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file BEST_Model_gbert_base_Ensemble_best_model/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at BEST_Model_gbert_base_Ensemble_best_model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 100\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----- 3. Predict -----#\n",
    "# Load test data\n",
    "X_test = list(anno)\n",
    "X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized1 = tokenizer1(X_test, padding=True, truncation=True, max_length=512)\n",
    "X_test_tokenized2 = tokenizer2(X_test, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "# Create torch dataset\n",
    "test_dataset = Dataset(X_test_tokenized)\n",
    "test_dataset1 = Dataset(X_test_tokenized1)\n",
    "test_dataset2 = Dataset(X_test_tokenized2)\n",
    "\n",
    "# Load trained models\n",
    "model = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_Toxicity_Ensemble_best_model\", num_labels=2)\n",
    "model1 = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_Electra_with_Germeval_training_run5_best_model\", num_labels=2)\n",
    "model2 = AutoModelForSequenceClassification.from_pretrained(f\"BEST_Model_gbert_base_Ensemble_best_model\", num_labels=2)\n",
    "\n",
    "# Define test trainer\n",
    "test_trainer = Trainer(model)\n",
    "test_trainer1 = Trainer(model1)\n",
    "test_trainer2 = Trainer(model2)\n",
    "\n",
    "# Make prediction\n",
    "raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "raw_pred1, _1, _1 = test_trainer1.predict(test_dataset1)\n",
    "raw_pred2, _2, _2 = test_trainer2.predict(test_dataset2)\n",
    "\n",
    "# Preprocess raw predictions\n",
    "y_pred = np.argmax(raw_pred, axis=1)\n",
    "y_pred1 = np.argmax(raw_pred1, axis=1)\n",
    "y_pred2 = np.argmax(raw_pred2, axis=1)\n",
    "\n",
    "sum_array = np.add(raw_pred, raw_pred1)\n",
    "sum_array = np.add(sum_array, raw_pred2)\n",
    "\n",
    "multi = np.multiply(sum_array, 0.5)\n",
    "\n",
    "y_pred_soft = np.argmax(multi, axis=1)\n",
    "y_pred_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3ad1426b-d940-490b-98da-620a0ef0117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = y_pred_soft.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "281913a3-6dd5-4160-ac8d-da1eb3294223",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>model_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1726998</th>\n",
       "      <td>@MichaelZimlich @GtzFrmming WÃ¤re auch fÃ¼r dies...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193770</th>\n",
       "      <td>@cdljsjh2 @MarionaMarione @Karl_Lauterbach War...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text  model_predictions\n",
       "1726998  @MichaelZimlich @GtzFrmming WÃ¤re auch fÃ¼r dies...                  0\n",
       "1193770  @cdljsjh2 @MarionaMarione @Karl_Lauterbach War...                  0"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append model predictions to the dataframe\n",
    "anno_df[\"model_predictions\"] = preds\n",
    "anno_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f3f4f138-1833-491c-b8c7-dc81aa7858f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "anno_df.to_csv(\"sanity_check.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7f309345-a0df-497c-9944-f1efce00063f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0, 78],\n",
       "       [ 1, 22]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Value counts of the classes\n",
    "np.array(np.unique(y_pred1, return_counts=True)).T\n",
    "## --> 16.33 % (15767 1 und 80808 0)sind Hate Tweets bei 100k Preds"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
