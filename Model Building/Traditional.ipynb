{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install nltk\n",
    "!pip install ipynb\n",
    "!pip install s3fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sys\n",
    "from ipynb.fs.full.eval_metrics import *\n",
    "import json\n",
    "import s3fs\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opening JSON file\n",
    "with open('../credentials.json', 'r') as openfile:\n",
    " \n",
    "    # Reading from json file\n",
    "    json_object = json.load(openfile)\n",
    "    key = json_object[\"key\"]\n",
    "    secret = json_object[\"secret_key\"]\n",
    "    bucket_name = json_object[\"bucket_name\"]\n",
    "\n",
    "s3 = s3fs.S3FileSystem(anon=False,key=key,secret=secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import sys\n",
    "from ipynb.fs.full.eval_metrics import *\n",
    "import json\n",
    "import s3fs\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preProcess(tweet):\n",
    "    tokens = nltk.word_tokenize(tweet)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    tokens = [w for w in tokens if w.isalpha()]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweetToFeatures(tokensList):\n",
    "    fdist = nltk.FreqDist(tokensList)\n",
    "    dictionary = dict(fdist)\n",
    "    s = pd.Series(dictionary)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = preProcess(data[\"Text\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter(tokens):\n",
    "    return [w for w in tokens if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = filter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = tweetToFeatures(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWordsPerTweet = []\n",
    "for tweet in data[\"Text\"]:\n",
    "    tokens = preProcess(tweet)\n",
    "    bagOfWords = tweetToFeatures(tokens)\n",
    "    bagOfWordsPerTweet.append(bagOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWords = pd.DataFrame(bagOfWordsPerTweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWords = bagOfWords.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filterUniqueWords(featureSpace):\n",
    "        toDelete = []\n",
    "        newFs = featureSpace.copy()\n",
    "        for col in newFs:\n",
    "            if(sum(newFs[col]) == 1.0):\n",
    "                toDelete.append(col)\n",
    "        for word,value in newFs.astype(bool).sum(axis=0).iteritems():\n",
    "            if(value == 1):\n",
    "                toDelete.append(word)\n",
    "        newFs = newFs.drop(list(set(toDelete)), axis=1)\n",
    "        return newFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bagOfWords = filterUniqueWords(bagOfWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors = bagOfWords.values\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(vectors, data['majority_vote'], test_size=0.2, random_state = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Naive Bayes<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB().fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, balanced_accuracy_score, f1_score, matthews_corrcoef, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = [make_scorer(accuracy_score),\n",
    "           make_scorer(balanced_accuracy_score),\n",
    "           make_scorer(f1_score, average='macro'),\n",
    "           make_scorer(f1_score, average='micro'),\n",
    "           make_scorer(f1_score, average=None, labels = [1]),\n",
    "           make_scorer(f1_score, average=None, labels = [2]),\n",
    "           make_scorer(f1_score, average=None, labels = [3]),\n",
    "           make_scorer(f1_score, average='weighted'),\n",
    "           make_scorer(matthews_corrcoef),\n",
    "           make_scorer(precision_score, average=None, labels = [1]),\n",
    "           make_scorer(precision_score, average=None, labels = [2]),\n",
    "           make_scorer(precision_score, average=None, labels = [3]),\n",
    "           make_scorer(precision_score, average='macro'),\n",
    "           make_scorer(precision_score, average='micro'),\n",
    "           make_scorer(precision_score, average='weighted'),\n",
    "           make_scorer(recall_score, average=None, labels = [1]),\n",
    "           make_scorer(recall_score, average=None, labels = [2]),\n",
    "           make_scorer(recall_score, average=None, labels = [3]),\n",
    "           make_scorer(recall_score, average='macro'),\n",
    "           make_scorer(recall_score, average='micro'),\n",
    "           make_scorer(recall_score, average='weighted')\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StratifiedShuffleSplit(n_splits=5, random_state=42, test_size=0.2,\n",
       "            train_size=None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(scoring):\n",
    "    for score in scoring:\n",
    "        scores = cross_val_score(clf, vectors, data['majority_vote'], scoring=score, cv = sss)\n",
    "        print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7310344827586207\n",
      "0.6781944444444445\n",
      "0.6802664647273533\n",
      "0.7310344827586207\n",
      "0.8075181954292117\n",
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.7285343625797823\n",
      "0.36175784133255184\n",
      "0.7980889746173032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6836790164593296\n",
      "0.7310344827586207\n",
      "0.7270758971399401\n",
      "0.8175000000000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.6781944444444445\n",
      "0.7310344827586207\n",
      "0.7310344827586207\n"
     ]
    }
   ],
   "source": [
    "report(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVM<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6956896551724138\n",
      "0.5295833333333333\n",
      "0.48437300499443925\n",
      "0.6956896551724139\n",
      "0.814389323985606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6095516087497094\n",
      "0.11375759969301968\n",
      "0.7031866748269591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.6104317212518634\n",
      "0.6956896551724138\n",
      "0.6456146346768997\n",
      "0.9675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.5295833333333333\n",
      "0.6956896551724138\n",
      "0.6956896551724138\n"
     ]
    }
   ],
   "source": [
    "report(scoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Pipeline for comparing methods<h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install spacy\n",
    "!python -m spacy download de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.lang.de.examples import sentences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('de_core_news_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(text):\n",
    "    doc = nlp(text)\n",
    "    return [word.lemma_ for word in doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalizationMethods = [\"None\", \"lower\", \"lemmatization\", \"lemmatizationAndLower\"]\n",
    "def normalize(tweetText, approach):\n",
    "    if(approach == \"None\"):\n",
    "        tokens = nltk.word_tokenize(tweetText)\n",
    "        return tokens\n",
    "    elif(approach == \"lower\"):\n",
    "        tokens = nltk.word_tokenize(tweetText)\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        return tokens\n",
    "    elif(approach == \"lemmatization\"):\n",
    "        doc = nlp(tweetText)\n",
    "        tokens = lemmatize(tweetText)\n",
    "        return tokens\n",
    "    elif(approach == \"lemmatizationAndLower\"):\n",
    "        doc = nlp(tweetText)\n",
    "        tokens = lemmatize(tweetText)\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterMethods = [\"None\", \"punctuation\", \"punctuationAndStopwords\"]\n",
    "def filter(tokens, approach):\n",
    "    if(approach == \"None\"):\n",
    "        return tokens\n",
    "    elif(approach == \"punctuation\"):\n",
    "        return [w for w in tokens if w.isalpha()]\n",
    "    elif(approach == \"punctuationAndStopwords\"):\n",
    "        return [w for w in tokens if w.isalpha() and w.lower()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureMethods = [\"tf\"]\n",
    "def textToFeatures(tokensList, approach):\n",
    "    if(approach == \"tf\"):\n",
    "        fdist = nltk.FreqDist(tokensList)\n",
    "        dictionary = dict(fdist)\n",
    "        s = pd.Series(dictionary)\n",
    "        return s\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSpaceFilterMethods = [\"None\", \"uniqueWords\"]\n",
    "def filterFs(featureSpace, filterMethod):\n",
    "    if(filterMethod == \"None\"):\n",
    "        return featureSpace\n",
    "    elif(filterMethod == \"uniqueWords\"):\n",
    "        toDelete = []\n",
    "        newFs = featureSpace.copy()\n",
    "        for col in newFs:\n",
    "            if(sum(newFs[col]) == 1.0):\n",
    "                toDelete.append(col)\n",
    "        for word,value in newFs.astype(bool).sum(axis=0).iteritems():\n",
    "            if(value == 1):\n",
    "                toDelete.append(word)\n",
    "        newFs = newFs.drop(list(set(toDelete)), axis=1)\n",
    "        return newFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureSpaceTransformationMethods = [\"None\"]\n",
    "def transformFeatureSpace(featureSpace, transformationMethod):\n",
    "    if(transformationMethod == \"None\"):\n",
    "        return featureSpace\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildFeatureSpace(normalizationApproach, filterApproach, featureMethod, filterFeatureSpace):\n",
    "    featuresPerTweet = []\n",
    "    for tweet in df[\"Text\"]:\n",
    "        tokens = normalize(tweet, normalizationApproach)\n",
    "        tokens = filter(tokens, filterApproach)\n",
    "        features = textToFeatures(tokens, featureMethod)\n",
    "        featuresPerTweet.append(features)\n",
    "    featureSpace = pd.DataFrame(featuresPerTweet)\n",
    "    featureSpace = featureSpace.fillna(0)\n",
    "    featureSpace = filterFs(featureSpace, filterFeatureSpace)\n",
    "    return featureSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\"bayes\", \"svm\", \"sgdc\", \"randomForest\"]\n",
    "def classifyAndEvaluate(featureSpace, classifier):\n",
    "    sss = StratifiedShuffleSplit(n_splits=5, test_size=0.2, random_state=42)\n",
    "    clf = None\n",
    "    if(classifier == \"bayes\"):\n",
    "        clf = MultinomialNB()\n",
    "    elif(classifier == \"svm\"):\n",
    "        clf = svm.SVC(gamma=\"scale\")\n",
    "    elif(classifier == \"sgdc\"):\n",
    "        clf = SGDClassifier(loss=\"hinge\", penalty=\"l2\", max_iter=5)\n",
    "    elif(classifier == \"randomForest\"):\n",
    "        clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    vectors = featureSpace.values\n",
    "    annotation = df[\"majority_vote\"]\n",
    "    scores = cross_val_score(clf, vectors, annotation, cv=sss)\n",
    "    print(scores.mean())\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getScores(normalizationApproach, filterApproach, featureMethod, filterFeatureSpace, classifier):\n",
    "    featureSpace = buildFeatureSpace(normalizationApproach, filterApproach, featureMethod, filterFeatureSpace)\n",
    "    scores = classifyAndEvaluate(featureSpace, classifier)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareAndPrint():\n",
    "    print(\"\\t\".join([\"Normalization\", \"Filtering\", \"Fspace\", \"Fspace-Filter\", \"Classifier\", \"Precision\"]))\n",
    "    for normalization in normalizationMethods:\n",
    "        for filtering in filterMethods:\n",
    "            for fspace in featureMethods:\n",
    "                for fspaceFilter in featureSpaceFilterMethods:\n",
    "                    for classifier in classifiers:\n",
    "                        scores = getScores(normalization, filtering, fspace, fspaceFilter, classifier)\n",
    "                        precision = scores.mean()\n",
    "                        print(\"\\t\".join([normalization, filtering, fspace, fspaceFilter, classifier, str(precision)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalization\tFiltering\tFspace\tFspace-Filter\tClassifier\tPrecision\n",
      "0.7318965517241379\n",
      "None\tNone\ttf\tNone\tbayes\t0.7318965517241379\n",
      "0.6965517241379311\n",
      "None\tNone\ttf\tNone\tsvm\t0.6965517241379311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6948275862068967\n",
      "None\tNone\ttf\tNone\tsgdc\t0.6948275862068967\n",
      "0.6922413793103448\n",
      "None\tNone\ttf\tNone\trandomForest\t0.6922413793103448\n",
      "0.7405172413793102\n",
      "None\tNone\ttf\tuniqueWords\tbayes\t0.7405172413793102\n",
      "0.6974137931034482\n",
      "None\tNone\ttf\tuniqueWords\tsvm\t0.6974137931034482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6991379310344829\n",
      "None\tNone\ttf\tuniqueWords\tsgdc\t0.6991379310344829\n",
      "0.7\n",
      "None\tNone\ttf\tuniqueWords\trandomForest\t0.7\n",
      "0.7241379310344828\n",
      "None\tpunctuation\ttf\tNone\tbayes\t0.7241379310344828\n",
      "0.6844827586206896\n",
      "None\tpunctuation\ttf\tNone\tsvm\t0.6844827586206896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6741379310344828\n",
      "None\tpunctuation\ttf\tNone\tsgdc\t0.6741379310344828\n",
      "0.6905172413793104\n",
      "None\tpunctuation\ttf\tNone\trandomForest\t0.6905172413793104\n",
      "0.7103448275862069\n",
      "None\tpunctuation\ttf\tuniqueWords\tbayes\t0.7103448275862069\n",
      "0.6905172413793104\n",
      "None\tpunctuation\ttf\tuniqueWords\tsvm\t0.6905172413793104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6887931034482758\n",
      "None\tpunctuation\ttf\tuniqueWords\tsgdc\t0.6887931034482758\n",
      "0.6956896551724138\n",
      "None\tpunctuation\ttf\tuniqueWords\trandomForest\t0.6956896551724138\n",
      "0.7241379310344828\n",
      "None\tpunctuationAndStopwords\ttf\tNone\tbayes\t0.7241379310344828\n",
      "0.6844827586206896\n",
      "None\tpunctuationAndStopwords\ttf\tNone\tsvm\t0.6844827586206896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905172413793104\n",
      "None\tpunctuationAndStopwords\ttf\tNone\tsgdc\t0.6905172413793104\n",
      "0.6905172413793104\n",
      "None\tpunctuationAndStopwords\ttf\tNone\trandomForest\t0.6905172413793104\n",
      "0.7103448275862069\n",
      "None\tpunctuationAndStopwords\ttf\tuniqueWords\tbayes\t0.7103448275862069\n",
      "0.6905172413793104\n",
      "None\tpunctuationAndStopwords\ttf\tuniqueWords\tsvm\t0.6905172413793104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6879310344827585\n",
      "None\tpunctuationAndStopwords\ttf\tuniqueWords\tsgdc\t0.6879310344827585\n",
      "0.6956896551724138\n",
      "None\tpunctuationAndStopwords\ttf\tuniqueWords\trandomForest\t0.6956896551724138\n",
      "0.7448275862068965\n",
      "lower\tNone\ttf\tNone\tbayes\t0.7448275862068965\n",
      "0.7025862068965518\n",
      "lower\tNone\ttf\tNone\tsvm\t0.7025862068965518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6879310344827585\n",
      "lower\tNone\ttf\tNone\tsgdc\t0.6879310344827585\n",
      "0.6956896551724138\n",
      "lower\tNone\ttf\tNone\trandomForest\t0.6956896551724138\n",
      "0.743103448275862\n",
      "lower\tNone\ttf\tuniqueWords\tbayes\t0.743103448275862\n",
      "0.7025862068965518\n",
      "lower\tNone\ttf\tuniqueWords\tsvm\t0.7025862068965518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6862068965517242\n",
      "lower\tNone\ttf\tuniqueWords\tsgdc\t0.6862068965517242\n",
      "0.7112068965517241\n",
      "lower\tNone\ttf\tuniqueWords\trandomForest\t0.7112068965517241\n",
      "0.7379310344827587\n",
      "lower\tpunctuation\ttf\tNone\tbayes\t0.7379310344827587\n",
      "0.693103448275862\n",
      "lower\tpunctuation\ttf\tNone\tsvm\t0.693103448275862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7025862068965518\n",
      "lower\tpunctuation\ttf\tNone\tsgdc\t0.7025862068965518\n",
      "0.7008620689655173\n",
      "lower\tpunctuation\ttf\tNone\trandomForest\t0.7008620689655173\n",
      "0.7310344827586207\n",
      "lower\tpunctuation\ttf\tuniqueWords\tbayes\t0.7310344827586207\n",
      "0.6956896551724138\n",
      "lower\tpunctuation\ttf\tuniqueWords\tsvm\t0.6956896551724138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6663793103448276\n",
      "lower\tpunctuation\ttf\tuniqueWords\tsgdc\t0.6663793103448276\n",
      "0.7086206896551724\n",
      "lower\tpunctuation\ttf\tuniqueWords\trandomForest\t0.7086206896551724\n",
      "0.7379310344827587\n",
      "lower\tpunctuationAndStopwords\ttf\tNone\tbayes\t0.7379310344827587\n",
      "0.693103448275862\n",
      "lower\tpunctuationAndStopwords\ttf\tNone\tsvm\t0.693103448275862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905172413793104\n",
      "lower\tpunctuationAndStopwords\ttf\tNone\tsgdc\t0.6905172413793104\n",
      "0.7008620689655173\n",
      "lower\tpunctuationAndStopwords\ttf\tNone\trandomForest\t0.7008620689655173\n",
      "0.7310344827586207\n",
      "lower\tpunctuationAndStopwords\ttf\tuniqueWords\tbayes\t0.7310344827586207\n",
      "0.6956896551724138\n",
      "lower\tpunctuationAndStopwords\ttf\tuniqueWords\tsvm\t0.6956896551724138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6887931034482759\n",
      "lower\tpunctuationAndStopwords\ttf\tuniqueWords\tsgdc\t0.6887931034482759\n",
      "0.7086206896551724\n",
      "lower\tpunctuationAndStopwords\ttf\tuniqueWords\trandomForest\t0.7086206896551724\n",
      "0.7353448275862069\n",
      "lemmatization\tNone\ttf\tNone\tbayes\t0.7353448275862069\n",
      "0.6956896551724137\n",
      "lemmatization\tNone\ttf\tNone\tsvm\t0.6956896551724137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_stochastic_gradient.py:696: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6905172413793104\n",
      "lemmatization\tNone\ttf\tNone\tsgdc\t0.6905172413793104\n"
     ]
    }
   ],
   "source": [
    "compareAndPrint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import svm\n",
    "\n",
    "def my_custom_metric(y_true, y_pred):\n",
    "    test_list = y_true\n",
    "    # Compute Evaluation Metrics\n",
    "    f = f1_multiclass(test_list, y_pred)\n",
    "    p = p_multiclass(test_list, y_pred)\n",
    "    r = recall_multiclass(test_list, y_pred)\n",
    "    a = accuracy_score(test_list, y_pred)\n",
    "    ba = balanced_accuracy_score(test_list, y_pred)\n",
    "    prs = precision_recall_fscore_support(test_list, y_pred)\n",
    "    m = matthews_corrcoef(test_list,y_pred)\n",
    "\n",
    "    results = {}\n",
    "    results[\"acc\"] = a\n",
    "    results[\"f1\"] = f\n",
    "    results[\"precision\"] = p\n",
    "    results[\"recall\"] = r\n",
    "    results[\"bal_acc\"] = ba\n",
    "    results[\"prfs\"] = prs\n",
    "    results[\"mcc\"] = m\n",
    "    return results\n",
    "\n",
    "def fold_values(fold_f, fold_number):\n",
    "    folds = pd.DataFrame(columns=[\"Model\", \"F1_Score\"])\n",
    "    models = []\n",
    "    f1s = []\n",
    "    p = []\n",
    "    r = []\n",
    "\n",
    "    for i in kfold_df[f\"model_fold_{fold_number}\"]:\n",
    "        name = i.get(\"name\")\n",
    "        f1 = i.get(\"custom_metric_score\").get(\"f1\").get(\"f1_weighted\")\n",
    "        pr = i.get(\"custom_metric_score\").get(\"precision\").get(\"precision_weighted\")\n",
    "        re = i.get(\"custom_metric_score\").get(\"recall\").get(\"recall_weighted\")\n",
    "        models.append(name)\n",
    "        f1s.append(f1)\n",
    "        p.append(pr)\n",
    "        r.append(re)\n",
    "\n",
    "\n",
    "    folds[\"Model\"] = models\n",
    "    folds[\"F1_Score\"] = f1s\n",
    "    folds[\"Precision\"] = p\n",
    "    folds[\"Recall\"] = r\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold Number: 1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.32      0.41        72\n",
      "           1       0.74      0.89      0.81       160\n",
      "\n",
      "    accuracy                           0.71       232\n",
      "   macro avg       0.65      0.60      0.61       232\n",
      "weighted avg       0.69      0.71      0.68       232\n",
      "\n",
      "Fold Number: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559/300311922.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kfold_df = kfold_df.append(test_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.29      0.39        72\n",
      "           1       0.74      0.90      0.81       160\n",
      "\n",
      "    accuracy                           0.71       232\n",
      "   macro avg       0.65      0.60      0.60       232\n",
      "weighted avg       0.69      0.71      0.68       232\n",
      "\n",
      "Fold Number: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559/300311922.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kfold_df = kfold_df.append(test_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.39      0.50        72\n",
      "           1       0.77      0.92      0.84       160\n",
      "\n",
      "    accuracy                           0.75       232\n",
      "   macro avg       0.73      0.65      0.67       232\n",
      "weighted avg       0.74      0.75      0.73       232\n",
      "\n",
      "Fold Number: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559/300311922.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kfold_df = kfold_df.append(test_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.31      0.42        71\n",
      "           1       0.75      0.93      0.83       160\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.70      0.62      0.62       231\n",
      "weighted avg       0.72      0.74      0.70       231\n",
      "\n",
      "Fold Number: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559/300311922.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kfold_df = kfold_df.append(test_)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.39      0.49        72\n",
      "           1       0.77      0.91      0.83       159\n",
      "\n",
      "    accuracy                           0.75       231\n",
      "   macro avg       0.72      0.65      0.66       231\n",
      "weighted avg       0.74      0.75      0.73       231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_559/300311922.py:65: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  kfold_df = kfold_df.append(test_)\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "from sklearn import metrics\n",
    "\n",
    "train_test_number = [1,2,3,4,5]\n",
    "train_file_name = \"train.csv\"\n",
    "test_file_name = \"test.csv\"\n",
    "kfold_df = pd.DataFrame()\n",
    "\n",
    "for train_index in train_test_number:\n",
    "    print(f\"Fold Number: {train_index}\")\n",
    "    # Read data\n",
    "    with s3.open(f\"{bucket_name}/KFOLD{train_index}/{train_file_name}\",'r') as file:\n",
    "        data = pd.read_csv(file)\n",
    "    with s3.open(f\"{bucket_name}/KFOLD{train_index}/{test_file_name}\",'r') as file:\n",
    "        test_data = pd.read_csv(file)\n",
    "\n",
    "    train_text = data['Text']\n",
    "    train_labels = data['majority_vote']\n",
    "    test_text = test_data['Text']\n",
    "    test_labels = test_data['majority_vote']\n",
    "    \n",
    "    # Tokenize the words\n",
    "    train_text_clean = train_text.apply(nltk.word_tokenize)\n",
    "    test_text_clean = test_text.apply(nltk.word_tokenize)\n",
    "\n",
    "    # Remove stop words\n",
    "    stop_words=set(nltk.corpus.stopwords.words(\"german\"))\n",
    "    train_text_clean = train_text_clean.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "    test_text_clean = test_text_clean.apply(lambda x: [item for item in x if item not in stop_words])\n",
    "\n",
    "    # Remove numbers, punctuation and special characters (only keep words)\n",
    "    regex = '[a-z]+'\n",
    "    train_text_clean = train_text_clean.apply(lambda x: [item for item in x if re.match(regex, item)])\n",
    "    test_text_clean = test_text_clean.apply(lambda x: [item for item in x if re.match(regex, item)])\n",
    "\n",
    "    # Lemmatization\n",
    "    lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "    train_text_clean = train_text_clean.apply(lambda x: [lem.lemmatize(item, pos='v') for item in x])\n",
    "    test_text_clean = test_text_clean.apply(lambda x: [lem.lemmatize(item, pos='v') for item in x])\n",
    "\n",
    "    # Join the words again to form sentences\n",
    "    train_text_clean = train_text_clean.apply(lambda x: \" \".join(x))\n",
    "    test_text_clean = test_text_clean.apply(lambda x: \" \".join(x))\n",
    "    \n",
    "    # Tfidf vectorization\n",
    "    vectorizer = TfidfVectorizer()\n",
    "\n",
    "    X_train = vectorizer.fit_transform(train_text)\n",
    "    X_test = vectorizer.transform(test_text)\n",
    "    y_train = train_labels\n",
    "    y_test = test_labels\n",
    "    \n",
    "    clf = svm.SVC(kernel = \"linear\")\n",
    "    # Training the classifier\n",
    "    clf_trained = clf.fit(X_train,y_train)\n",
    "    # Scoring the classifier\n",
    "    clf_trained.score(X_test,y_test)\n",
    "\n",
    "    #extract the predictions of the model\n",
    "    test_pred_svm = clf_trained.predict(X_test)\n",
    "    #print the classification report\n",
    "    print (metrics.classification_report(y_test, test_pred_svm))\n",
    "    test = my_custom_metric(y_test, test_pred_svm) \n",
    "    test_ = pd.DataFrame([test])\n",
    "    #kfold_df = kfold_df.append(test_)\n",
    "    test_.to_csv(f\"SVM_KFOLD_{train_index}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_df = kfold_df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>acc</th>\n",
       "      <th>bal_acc</th>\n",
       "      <th>prfs</th>\n",
       "      <th>mcc</th>\n",
       "      <th>f1_micro</th>\n",
       "      <th>f1_macro</th>\n",
       "      <th>f1_weighted</th>\n",
       "      <th>precision_micro</th>\n",
       "      <th>precision_macro</th>\n",
       "      <th>precision_weighted</th>\n",
       "      <th>recall_micro</th>\n",
       "      <th>recall_macro</th>\n",
       "      <th>recall_weighted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.603472</td>\n",
       "      <td>([0.5609756097560976, 0.743455497382199], [0.3...</td>\n",
       "      <td>0.250999</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.608098</td>\n",
       "      <td>0.684347</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.652216</td>\n",
       "      <td>0.686824</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.603472</td>\n",
       "      <td>0.711207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>([0.5675675675675675, 0.7384615384615385], [0....</td>\n",
       "      <td>0.242189</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.598294</td>\n",
       "      <td>0.679077</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.653015</td>\n",
       "      <td>0.685425</td>\n",
       "      <td>0.711207</td>\n",
       "      <td>0.595833</td>\n",
       "      <td>0.711207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.653819</td>\n",
       "      <td>([0.6829268292682927, 0.7696335078534031], [0....</td>\n",
       "      <td>0.373129</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.666591</td>\n",
       "      <td>0.731459</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.726280</td>\n",
       "      <td>0.742725</td>\n",
       "      <td>0.754310</td>\n",
       "      <td>0.653819</td>\n",
       "      <td>0.754310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>([0.6470588235294118, 0.751269035532995], [0.3...</td>\n",
       "      <td>0.305861</td>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.624090</td>\n",
       "      <td>0.703089</td>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.699164</td>\n",
       "      <td>0.719239</td>\n",
       "      <td>0.735931</td>\n",
       "      <td>0.617430</td>\n",
       "      <td>0.735931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.650419</td>\n",
       "      <td>([0.6666666666666666, 0.7671957671957672], [0....</td>\n",
       "      <td>0.361279</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.662281</td>\n",
       "      <td>0.726703</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.716931</td>\n",
       "      <td>0.735862</td>\n",
       "      <td>0.748918</td>\n",
       "      <td>0.650419</td>\n",
       "      <td>0.748918</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index       acc   bal_acc  \\\n",
       "0      0  0.711207  0.603472   \n",
       "1      0  0.711207  0.595833   \n",
       "2      0  0.754310  0.653819   \n",
       "3      0  0.735931  0.617430   \n",
       "4      0  0.748918  0.650419   \n",
       "\n",
       "                                                prfs       mcc  f1_micro  \\\n",
       "0  ([0.5609756097560976, 0.743455497382199], [0.3...  0.250999  0.711207   \n",
       "1  ([0.5675675675675675, 0.7384615384615385], [0....  0.242189  0.711207   \n",
       "2  ([0.6829268292682927, 0.7696335078534031], [0....  0.373129  0.754310   \n",
       "3  ([0.6470588235294118, 0.751269035532995], [0.3...  0.305861  0.735931   \n",
       "4  ([0.6666666666666666, 0.7671957671957672], [0....  0.361279  0.748918   \n",
       "\n",
       "   f1_macro  f1_weighted  precision_micro  precision_macro  \\\n",
       "0  0.608098     0.684347         0.711207         0.652216   \n",
       "1  0.598294     0.679077         0.711207         0.653015   \n",
       "2  0.666591     0.731459         0.754310         0.726280   \n",
       "3  0.624090     0.703089         0.735931         0.699164   \n",
       "4  0.662281     0.726703         0.748918         0.716931   \n",
       "\n",
       "   precision_weighted  recall_micro  recall_macro  recall_weighted  \n",
       "0            0.686824      0.711207      0.603472         0.711207  \n",
       "1            0.685425      0.711207      0.595833         0.711207  \n",
       "2            0.742725      0.754310      0.653819         0.754310  \n",
       "3            0.719239      0.735931      0.617430         0.735931  \n",
       "4            0.735862      0.748918      0.650419         0.748918  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute Result metrics\n",
    "\n",
    "f1_micro_l = []\n",
    "f1_macro_l = []\n",
    "f1_w_l = []\n",
    "\n",
    "p_micro_l = []\n",
    "p_macro_l = []\n",
    "p_w_l = []\n",
    "\n",
    "r_micro_l = []\n",
    "r_macro_l = []\n",
    "r_w_l = []\n",
    "\n",
    "for index, row in kfold_df.iterrows():\n",
    "    f1_micro = row[\"f1\"].get(\"f1_micro\")\n",
    "    f1_micro_l.append(f1_micro)\n",
    "    f1_macro = row[\"f1\"].get(\"f1_macro\")\n",
    "    f1_macro_l.append(f1_macro)\n",
    "    f1_w = row[\"f1\"].get(\"f1_weighted\")\n",
    "    f1_w_l.append(f1_w)\n",
    "    \n",
    "    p_micro = row[\"precision\"].get(\"precision_micro\")\n",
    "    p_micro_l.append(p_micro)\n",
    "    p_macro = row[\"precision\"].get(\"precision_macro\")\n",
    "    p_macro_l.append(p_macro)\n",
    "    p_w = row[\"precision\"].get(\"precision_weighted\")\n",
    "    p_w_l.append(p_w)\n",
    "    \n",
    "    r_micro = row[\"recall\"].get(\"recall_micro\")\n",
    "    r_micro_l.append(r_micro)\n",
    "    r_macro = row[\"recall\"].get(\"recall_macro\")\n",
    "    r_macro_l.append(r_macro)\n",
    "    r_w = row[\"recall\"].get(\"recall_weighted\")\n",
    "    r_w_l.append(r_w)\n",
    "    \n",
    "kfold_df[\"f1_micro\"] = f1_micro_l\n",
    "kfold_df[\"f1_macro\"] = f1_macro_l\n",
    "kfold_df[\"f1_weighted\"] = f1_w_l\n",
    "kfold_df = kfold_df.drop(\"f1\", axis=1)\n",
    "kfold_df[\"precision_micro\"] = p_micro_l\n",
    "kfold_df[\"precision_macro\"] = p_macro_l\n",
    "kfold_df[\"precision_weighted\"] = p_w_l\n",
    "kfold_df = kfold_df.drop(\"precision\", axis=1)\n",
    "kfold_df[\"recall_micro\"] = r_micro_l\n",
    "kfold_df[\"recall_macro\"] = r_macro_l\n",
    "kfold_df[\"recall_weighted\"] = r_w_l\n",
    "kfold_df = kfold_df.drop(\"recall\", axis=1)\n",
    "kfold_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_df.loc[\"Total\"] = kfold_df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.7323145245559038\n",
      "F1 Micro: 0.7323145245559038\n",
      "F1 Macro: 0.6318707895748974\n",
      "F1 Weighted: 0.704934938056964\n",
      "Precision Micro: 0.7323145245559038\n",
      "Precision Macro: 0.6895210843213938\n",
      "Precision Weighted: 0.7140149807626603\n",
      "Recall Micro: 0.7323145245559038\n",
      "Recall Macro: 0.6241947729353058\n",
      "Recall Weighted: 0.7323145245559038\n"
     ]
    }
   ],
   "source": [
    "# Results of the SVM model after 5-Fold Cross Validation:\n",
    "print(f\"Acc: {kfold_df['acc']['Total'] / 5}\")\n",
    "print(f\"F1 Micro: {kfold_df['f1_micro']['Total'] / 5}\")\n",
    "print(f\"F1 Macro: {kfold_df['f1_macro']['Total'] / 5}\")\n",
    "print(f\"F1 Weighted: {kfold_df['f1_weighted']['Total'] / 5}\")\n",
    "print(f\"Precision Micro: {kfold_df['precision_micro']['Total'] / 5}\")\n",
    "print(f\"Precision Macro: {kfold_df['precision_macro']['Total'] / 5}\")\n",
    "print(f\"Precision Weighted: {kfold_df['precision_weighted']['Total'] / 5}\")\n",
    "print(f\"Recall Micro: {kfold_df['recall_micro']['Total'] / 5}\")\n",
    "print(f\"Recall Macro: {kfold_df['recall_macro']['Total'] / 5}\")\n",
    "print(f\"Recall Weighted: {kfold_df['recall_weighted']['Total'] / 5}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f528865da84acfda39e25b2b9cc0a0ebf0f79a3ff93e0b4759131a22bc5fae8f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
