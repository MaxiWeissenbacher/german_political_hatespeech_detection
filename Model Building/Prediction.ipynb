{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "01d4c154-8b05-4e5b-aad2-acd7af640471",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "%%capture\n",
    "!pip install transformers\n",
    "!pip install datasets\n",
    "!pip install torchvision\n",
    "!pip install ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17d0185-925f-4649-907a-ebe3f2ec1ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from transformers import EarlyStoppingCallback\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report \n",
    "from transformers import get_scheduler\n",
    "from transformers import AdamW\n",
    "import shutil\n",
    "import os\n",
    "import torch\n",
    "from ipynb.fs.full.eval_metrics import *\n",
    "hello()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6196225a-8bf8-42c0-8e6b-4f28253fe61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create torch dataset\n",
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels:\n",
    "            item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db5b5f3-0ac6-45ca-a251-6ca1ca3214c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# before starting, empty the Cuda cache to have more memory space\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6efc5b01-879e-4e78-a936-be8ea38e1165",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../full_datasets/control_group_mentions_data_without_retweets.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3c5d59a-1b5b-40ad-a384-20a3de2bc290",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweets(von_n, bis_n):    \n",
    "    # Splitting up the tweets to avoid crashing the kernel\n",
    "    tweets = pd.read_csv(path)\n",
    "    # make sure no \"NA\" values are in the text column\n",
    "    tweets = tweets[tweets['text'].notna()]\n",
    "    print(len(tweets))\n",
    "     #400k zu 600k\n",
    "    von = von_n\n",
    "    bis = bis_n\n",
    "    tweets = tweets[von:bis]\n",
    "    len(tweets)\n",
    "\n",
    "    # Initialize the Tokenizers for each model\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"EIStakovskii/german_toxicity_classifier_plus_v2\")\n",
    "    tokenizer1 = AutoTokenizer.from_pretrained(\"german-nlp-group/electra-base-german-uncased\")\n",
    "    tokenizer2 = AutoTokenizer.from_pretrained(\"deepset/gbert-base\")\n",
    "    # ----- 3. Predict -----#\n",
    "    # Load test data\n",
    "    X_test = list(tweets[\"text\"])\n",
    "    X_test_tokenized = tokenizer(X_test, padding=True, truncation=True, max_length=512)\n",
    "    X_test_tokenized1 = tokenizer1(X_test, padding=True, truncation=True, max_length=512)\n",
    "    X_test_tokenized2 = tokenizer2(X_test, padding=True, truncation=True, max_length=512)\n",
    "\n",
    "    # Create torch dataset\n",
    "    test_dataset = Dataset(X_test_tokenized)\n",
    "    test_dataset1 = Dataset(X_test_tokenized1)\n",
    "    test_dataset2 = Dataset(X_test_tokenized2)\n",
    "\n",
    "    # Load trained models\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(f\"mox/german_toxicity_classifier_offensive_language_politicians\", num_labels=2)\n",
    "    model1 = AutoModelForSequenceClassification.from_pretrained(f\"mox/electra_german_uncased_offensive_language_politicians\", num_labels=2)\n",
    "    model2 = AutoModelForSequenceClassification.from_pretrained(f\"mox/gbert_base_offensive_language_politicians\", num_labels=2)\n",
    "\n",
    "    # Define test trainer\n",
    "    test_trainer = Trainer(model)\n",
    "    test_trainer1 = Trainer(model1)\n",
    "    test_trainer2 = Trainer(model2)\n",
    "\n",
    "    # Make prediction\n",
    "    print(\"Trainer 1\")\n",
    "    raw_pred, _, _ = test_trainer.predict(test_dataset)\n",
    "    print(\"Trainer 2\")\n",
    "    raw_pred1, _1, _1 = test_trainer1.predict(test_dataset1)\n",
    "    print(\"Trainer 3\")\n",
    "    raw_pred2, _2, _2 = test_trainer2.predict(test_dataset2)\n",
    "\n",
    "    # Preprocess raw predictions\n",
    "    y_pred = np.argmax(raw_pred, axis=1)\n",
    "    y_pred1 = np.argmax(raw_pred1, axis=1)\n",
    "    y_pred2 = np.argmax(raw_pred2, axis=1)\n",
    "\n",
    "    sum_array = np.add(raw_pred, raw_pred1)\n",
    "    sum_array = np.add(sum_array, raw_pred2)\n",
    "\n",
    "    multi = np.multiply(sum_array, 0.5)\n",
    "\n",
    "    y_pred_soft = np.argmax(multi, axis=1)\n",
    "    y_pred_soft\n",
    "\n",
    "    preds = y_pred_soft.tolist()\n",
    "    # Append model predictions to the dataframe\n",
    "    tweets[\"model_predictions\"] = preds\n",
    "    tweets.head(2)\n",
    "    tweets.to_csv(f\"control_group_tweets_predicted_{von}_until_{bis}.csv\")\n",
    "    \n",
    "    del tweets\n",
    "    del X_test\n",
    "    del tokenizer\n",
    "    del tokenizer1\n",
    "    del tokenizer2\n",
    "    del X_test_tokenized\n",
    "    del X_test_tokenized1\n",
    "    del X_test_tokenized2\n",
    "    del test_dataset\n",
    "    del test_dataset1\n",
    "    del test_dataset2\n",
    "    del model\n",
    "    del model1\n",
    "    del model2\n",
    "    del test_trainer\n",
    "    del test_trainer1\n",
    "    del test_trainer2\n",
    "    del raw_pred\n",
    "    del raw_pred1\n",
    "    del raw_pred2\n",
    "    del y_pred\n",
    "    del y_pred1\n",
    "    del y_pred2\n",
    "    del sum_array\n",
    "    del multi\n",
    "    del y_pred_soft\n",
    "    del preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f95100b-c8e1-4ca9-8f0a-57842512e577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174/303617089.py:3: DtypeWarning: Columns (0,1,3,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "four_to_six = predict_tweets(400000,600000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "360a673c-de6b-4676-91f4-7e77f78d64e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174/303617089.py:3: DtypeWarning: Columns (0,1,3,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--german_toxicity_classifier_offensive_language_politicians/snapshots/5c0fe0dcb9e879ba2873ffc1ac5d9559a797846f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mox/german_toxicity_classifier_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"neutral\",\n",
      "    \"1\": \"toxic\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"neutral\": 0,\n",
      "    \"toxic\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--german_toxicity_classifier_offensive_language_politicians/snapshots/5c0fe0dcb9e879ba2873ffc1ac5d9559a797846f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at mox/german_toxicity_classifier_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--electra_german_uncased_offensive_language_politicians/snapshots/2154b3dbd5f9ccabbfc41d8ce4e376ee2edd684f/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"mox/electra_german_uncased_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--electra_german_uncased_offensive_language_politicians/snapshots/2154b3dbd5f9ccabbfc41d8ce4e376ee2edd684f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at mox/electra_german_uncased_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--gbert_base_offensive_language_politicians/snapshots/5f8183fc52b987a44f0b82ba67cbafd97613d824/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mox/gbert_base_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--gbert_base_offensive_language_politicians/snapshots/5f8183fc52b987a44f0b82ba67cbafd97613d824/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at mox/gbert_base_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "six_to_eight = predict_tweets(600000,800000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0af23431-ddfd-4211-ae1d-f44165c8b959",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174/303617089.py:3: DtypeWarning: Columns (0,1,3,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--german_toxicity_classifier_offensive_language_politicians/snapshots/5c0fe0dcb9e879ba2873ffc1ac5d9559a797846f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mox/german_toxicity_classifier_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"neutral\",\n",
      "    \"1\": \"toxic\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"neutral\": 0,\n",
      "    \"toxic\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--german_toxicity_classifier_offensive_language_politicians/snapshots/5c0fe0dcb9e879ba2873ffc1ac5d9559a797846f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at mox/german_toxicity_classifier_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--electra_german_uncased_offensive_language_politicians/snapshots/2154b3dbd5f9ccabbfc41d8ce4e376ee2edd684f/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"mox/electra_german_uncased_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--electra_german_uncased_offensive_language_politicians/snapshots/2154b3dbd5f9ccabbfc41d8ce4e376ee2edd684f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at mox/electra_german_uncased_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--gbert_base_offensive_language_politicians/snapshots/5f8183fc52b987a44f0b82ba67cbafd97613d824/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mox/gbert_base_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--gbert_base_offensive_language_politicians/snapshots/5f8183fc52b987a44f0b82ba67cbafd97613d824/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at mox/gbert_base_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 3\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eight_to_ten = predict_tweets(800000,1000000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77e6552-3a0f-466c-ad01-901ef3868bdd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1174/303617089.py:3: DtypeWarning: Columns (0,1,3,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/vocab.txt\n",
      "loading file tokenizer.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer.json\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/special_tokens_map.json\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--EIStakovskii--german_toxicity_classifier_plus_v2/snapshots/6c8e91acf96ceeb7f92386057251e3e988d759e6/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--german-nlp-group--electra-base-german-uncased/snapshots/5a79890051f8df23591f06710012d399b7e17d9b/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"german-nlp-group/electra-base-german-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading file vocab.txt from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/tokenizer_config.json\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--deepset--gbert-base/snapshots/4a45e506eccc3405ed2e2a0502995d3f7e483509/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"deepset/gbert-base\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--german_toxicity_classifier_offensive_language_politicians/snapshots/5c0fe0dcb9e879ba2873ffc1ac5d9559a797846f/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mox/german_toxicity_classifier_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"neutral\",\n",
      "    \"1\": \"toxic\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"neutral\": 0,\n",
      "    \"toxic\": 1\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--german_toxicity_classifier_offensive_language_politicians/snapshots/5c0fe0dcb9e879ba2873ffc1ac5d9559a797846f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at mox/german_toxicity_classifier_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--electra_german_uncased_offensive_language_politicians/snapshots/2154b3dbd5f9ccabbfc41d8ce4e376ee2edd684f/config.json\n",
      "Model config ElectraConfig {\n",
      "  \"_name_or_path\": \"mox/electra_german_uncased_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"ElectraForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"summary_activation\": \"gelu\",\n",
      "  \"summary_last_dropout\": 0.1,\n",
      "  \"summary_type\": \"first\",\n",
      "  \"summary_use_proj\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32767\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--electra_german_uncased_offensive_language_politicians/snapshots/2154b3dbd5f9ccabbfc41d8ce4e376ee2edd684f/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing ElectraForSequenceClassification.\n",
      "\n",
      "All the weights of ElectraForSequenceClassification were initialized from the model checkpoint at mox/electra_german_uncased_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use ElectraForSequenceClassification for predictions without further training.\n",
      "loading configuration file config.json from cache at /home/jovyan/.cache/huggingface/hub/models--mox--gbert_base_offensive_language_politicians/snapshots/5f8183fc52b987a44f0b82ba67cbafd97613d824/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"mox/gbert_base_offensive_language_politicians\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.26.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 31102\n",
      "}\n",
      "\n",
      "loading weights file pytorch_model.bin from cache at /home/jovyan/.cache/huggingface/hub/models--mox--gbert_base_offensive_language_politicians/snapshots/5f8183fc52b987a44f0b82ba67cbafd97613d824/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at mox/gbert_base_offensive_language_politicians.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8074' max='25000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8074/25000 17:10 < 35:59, 7.84 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ten_to_twelve = predict_tweets(1000000,1200000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f119082d-e840-4761-93ee-50a831bcf53e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_521/303617089.py:3: DtypeWarning: Columns (0,1,3,9,10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  tweets = pd.read_csv(path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1534833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "No `TrainingArguments` passed, using `output_dir=tmp_trainer`.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 1\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 2\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 200000\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer 3\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='865' max='25000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  865/25000 01:53 < 52:40, 7.64 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "twelve_to_fourteen = predict_tweets(1200000,1400000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e272a0df-f810-473d-bf9d-cfd9685ed6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourteen_to_end = predict_tweets(1400000,1534833)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "73123f3e-499d-4c10-b11f-f89d90e6815c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_409/2125364615.py:1: DtypeWarning: Columns (1,2,9,14,15,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  batch_1 = pd.read_csv(\"control_group_tweets_predicted_1000000_until_1200000.csv\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1 = pd.read_csv(\"control_group_tweets_predicted_1000000_until_1200000.csv\")\n",
    "len(batch_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6a516ddc-0295-46f8-a769-a38ddf697346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    167995\n",
       "1     32005\n",
       "Name: model_predictions, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_1.model_predictions.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c8973cc-6057-4983-a35a-5a42b82b3131",
   "metadata": {},
   "outputs": [],
   "source": [
    "del batch_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd409a1f-abca-4339-955b-f4edf79c8d72",
   "metadata": {},
   "source": [
    "# Merging Datasets again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37fb93ff-d38a-4571-8920-bed0b567f264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "files = glob.glob(\"../Predictions/*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de2237cf-540c-492d-97a3-31d695681d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,3,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,3,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,3,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,3,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,3,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n",
      "/tmp/ipykernel_974/3216205998.py:3: DtypeWarning: Columns (2,3,5,11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  csv = pd.read_csv(f)\n",
      "/tmp/ipykernel_974/3216205998.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df.append(csv)\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "for f in files:\n",
    "    csv = pd.read_csv(f)\n",
    "    df = df.append(csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7d4068c8-1ccd-4127-8a00-ad634023ad93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2150444"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bf7b46d0-19c4-44d3-b6f8-592070daa528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>author_tweets</th>\n",
       "      <th>author_description</th>\n",
       "      <th>author_location</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Partei</th>\n",
       "      <th>model_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1435940649572966400.0</td>\n",
       "      <td>CHARLYCAPRI4</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@SWagenknecht Sie sind gescheitert ,weil Sie d...</td>\n",
       "      <td>2022-03-31 23:51:42+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['SWagenknecht']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>528677411.0</td>\n",
       "      <td>jo711</td>\n",
       "      <td>6</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Ewiger Revolluzer :-) ,\\nBiker,Hundeverrckt.N...</td>\n",
       "      <td>jo</td>\n",
       "      <td>@SWagenknecht Mittlerweile langweilen Sie .\\nK...</td>\n",
       "      <td>2022-03-31 23:51:27+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['SWagenknecht']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>762265140.0</td>\n",
       "      <td>nimmdenbus</td>\n",
       "      <td>1574</td>\n",
       "      <td>118892.0</td>\n",
       "      <td>Take the bus! Prenez le bus! Mein Herz schlgt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@MarvinWendland1 @SWagenknecht @BinBerlinerIn ...</td>\n",
       "      <td>2022-03-31 23:50:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['MarvinWendland1', 'SWagenknecht', 'BinBerlin...</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>94034298.0</td>\n",
       "      <td>derstaatsanwalt</td>\n",
       "      <td>325</td>\n",
       "      <td>5762.0</td>\n",
       "      <td>Ius vigilantibus scriptum est | er/ihr | rt/fo...</td>\n",
       "      <td>Standort ausgeblendet</td>\n",
       "      <td>@voglerk @NiemaMovassat Mit Landleben hat das,...</td>\n",
       "      <td>2022-03-31 23:45:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['voglerk', 'NiemaMovassat']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>3098650023.0</td>\n",
       "      <td>emerald_fm</td>\n",
       "      <td>99</td>\n",
       "      <td>45077.0</td>\n",
       "      <td>HOL' DIR DEINEN OHRWURM!\\n+49-30-92094422\\n...</td>\n",
       "      <td>Prusse Hrouge, Berlin, Germany</td>\n",
       "      <td>@DietmarBartsch Alles Gute zum 63sten noch, He...</td>\n",
       "      <td>2022-03-31 23:45:30+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['DietmarBartsch']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>3601292</td>\n",
       "      <td>1148916458983964673</td>\n",
       "      <td>DagmarFreitag13</td>\n",
       "      <td>1280</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>MdB 1994-2021  SPD   Transatlantikerin  Atl...</td>\n",
       "      <td>Iserlohn, Deutschland</td>\n",
       "      <td>@JoSteiniger Eins so schlecht wie das andere. ...</td>\n",
       "      <td>2022-03-14 12:49:31+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['JoSteiniger']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>3601294</td>\n",
       "      <td>1148916458983964673</td>\n",
       "      <td>DagmarFreitag13</td>\n",
       "      <td>1280</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>MdB 1994-2021  SPD   Transatlantikerin  Atl...</td>\n",
       "      <td>Iserlohn, Deutschland</td>\n",
       "      <td>@JoSteiniger Unmittelbar nach der Flutkatastro...</td>\n",
       "      <td>2022-03-14 12:48:54+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['JoSteiniger']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>3601295</td>\n",
       "      <td>1470993750252007425</td>\n",
       "      <td>BauingM</td>\n",
       "      <td>1302</td>\n",
       "      <td>10748.0</td>\n",
       "      <td>Leben und leben lassen.\\nGlaube nur der Statis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jensspahn Die komplette Co2-Steuer gehrt abg...</td>\n",
       "      <td>2022-03-14 12:48:45+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['jensspahn']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>3601296</td>\n",
       "      <td>825765542816575489</td>\n",
       "      <td>SantorinRh</td>\n",
       "      <td>261</td>\n",
       "      <td>11781.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jensspahn Zum Ersten Mal bin ich der gleichen...</td>\n",
       "      <td>2022-03-14 12:48:10+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['jensspahn']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>3601299</td>\n",
       "      <td>3618908661</td>\n",
       "      <td>StefanHarders</td>\n",
       "      <td>594</td>\n",
       "      <td>18212.0</td>\n",
       "      <td>Engineer #ClimateEmergency #carfree #mdRzA #mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@klaus66online @Scratchstone @jensspahn Spritp...</td>\n",
       "      <td>2022-03-14 12:46:29+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['klaus66online', 'Scratchstone', 'jensspahn']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2150444 rows  17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0              author_id         username author_followers  \\\n",
       "0               1  1435940649572966400.0     CHARLYCAPRI4                1   \n",
       "1               2            528677411.0            jo711                6   \n",
       "2               3            762265140.0       nimmdenbus             1574   \n",
       "3               4             94034298.0  derstaatsanwalt              325   \n",
       "4               5           3098650023.0       emerald_fm               99   \n",
       "...           ...                    ...              ...              ...   \n",
       "199995    3601292    1148916458983964673  DagmarFreitag13             1280   \n",
       "199996    3601294    1148916458983964673  DagmarFreitag13             1280   \n",
       "199997    3601295    1470993750252007425          BauingM             1302   \n",
       "199998    3601296     825765542816575489       SantorinRh              261   \n",
       "199999    3601299             3618908661    StefanHarders              594   \n",
       "\n",
       "        author_tweets                                 author_description  \\\n",
       "0                14.0                                                NaN   \n",
       "1               308.0  Ewiger Revolluzer :-) ,\\nBiker,Hundeverrckt.N...   \n",
       "2            118892.0  Take the bus! Prenez le bus! Mein Herz schlgt...   \n",
       "3              5762.0  Ius vigilantibus scriptum est | er/ihr | rt/fo...   \n",
       "4             45077.0  HOL' DIR DEINEN OHRWURM!\\n+49-30-92094422\\n...   \n",
       "...               ...                                                ...   \n",
       "199995         4085.0  MdB 1994-2021  SPD   Transatlantikerin  Atl...   \n",
       "199996         4085.0  MdB 1994-2021  SPD   Transatlantikerin  Atl...   \n",
       "199997        10748.0  Leben und leben lassen.\\nGlaube nur der Statis...   \n",
       "199998        11781.0                                               \n",
       "199999        18212.0  Engineer #ClimateEmergency #carfree #mdRzA #mo...   \n",
       "\n",
       "                       author_location  \\\n",
       "0                                  NaN   \n",
       "1                                   jo   \n",
       "2                                  NaN   \n",
       "3                Standort ausgeblendet   \n",
       "4       Prusse Hrouge, Berlin, Germany   \n",
       "...                                ...   \n",
       "199995           Iserlohn, Deutschland   \n",
       "199996           Iserlohn, Deutschland   \n",
       "199997                             NaN   \n",
       "199998                             NaN   \n",
       "199999                             NaN   \n",
       "\n",
       "                                                     text  \\\n",
       "0       @SWagenknecht Sie sind gescheitert ,weil Sie d...   \n",
       "1       @SWagenknecht Mittlerweile langweilen Sie .\\nK...   \n",
       "2       @MarvinWendland1 @SWagenknecht @BinBerlinerIn ...   \n",
       "3       @voglerk @NiemaMovassat Mit Landleben hat das,...   \n",
       "4       @DietmarBartsch Alles Gute zum 63sten noch, He...   \n",
       "...                                                   ...   \n",
       "199995  @JoSteiniger Eins so schlecht wie das andere. ...   \n",
       "199996  @JoSteiniger Unmittelbar nach der Flutkatastro...   \n",
       "199997  @jensspahn Die komplette Co2-Steuer gehrt abg...   \n",
       "199998  @jensspahn Zum Ersten Mal bin ich der gleichen...   \n",
       "199999  @klaus66online @Scratchstone @jensspahn Spritp...   \n",
       "\n",
       "                       created_at quote_count retweets  replies  likes  \\\n",
       "0       2022-03-31 23:51:42+00:00           0        0      0.0    0.0   \n",
       "1       2022-03-31 23:51:27+00:00           0        0      0.0    0.0   \n",
       "2       2022-03-31 23:50:40+00:00           0        0      0.0    0.0   \n",
       "3       2022-03-31 23:45:33+00:00           0        0      0.0    0.0   \n",
       "4       2022-03-31 23:45:30+00:00           0        0      0.0    1.0   \n",
       "...                           ...         ...      ...      ...    ...   \n",
       "199995  2022-03-14 12:49:31+00:00         0.0      0.0      0.0    0.0   \n",
       "199996  2022-03-14 12:48:54+00:00         0.0      0.0      1.0    1.0   \n",
       "199997  2022-03-14 12:48:45+00:00         0.0      1.0      0.0    8.0   \n",
       "199998  2022-03-14 12:48:10+00:00         0.0      0.0      0.0    1.0   \n",
       "199999  2022-03-14 12:46:29+00:00         0.0      0.0      1.0    1.0   \n",
       "\n",
       "                                                mentioned            Runs  \\\n",
       "0                                        ['SWagenknecht']   Linke_polis_1   \n",
       "1                                        ['SWagenknecht']   Linke_polis_1   \n",
       "2       ['MarvinWendland1', 'SWagenknecht', 'BinBerlin...   Linke_polis_1   \n",
       "3                            ['voglerk', 'NiemaMovassat']   Linke_polis_1   \n",
       "4                                      ['DietmarBartsch']   Linke_polis_1   \n",
       "...                                                   ...             ...   \n",
       "199995                                    ['JoSteiniger']  CDUCSU_polis_3   \n",
       "199996                                    ['JoSteiniger']  CDUCSU_polis_3   \n",
       "199997                                      ['jensspahn']  CDUCSU_polis_3   \n",
       "199998                                      ['jensspahn']  CDUCSU_polis_3   \n",
       "199999     ['klaus66online', 'Scratchstone', 'jensspahn']  CDUCSU_polis_3   \n",
       "\n",
       "           Partei  model_predictions  \n",
       "0       Die Linke                  0  \n",
       "1       Die Linke                  0  \n",
       "2       Die Linke                  0  \n",
       "3       Die Linke                  0  \n",
       "4       Die Linke                  0  \n",
       "...           ...                ...  \n",
       "199995    CSU/CDU                  0  \n",
       "199996    CSU/CDU                  0  \n",
       "199997    CSU/CDU                  0  \n",
       "199998    CSU/CDU                  0  \n",
       "199999    CSU/CDU                  0  \n",
       "\n",
       "[2150444 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop([\"Unnamed: 0.2\", \"Unnamed: 0.1\"], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5c1678c3-58b7-430d-8181-947a231fb771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>author_id</th>\n",
       "      <th>username</th>\n",
       "      <th>author_followers</th>\n",
       "      <th>author_tweets</th>\n",
       "      <th>author_description</th>\n",
       "      <th>author_location</th>\n",
       "      <th>text</th>\n",
       "      <th>created_at</th>\n",
       "      <th>quote_count</th>\n",
       "      <th>retweets</th>\n",
       "      <th>replies</th>\n",
       "      <th>likes</th>\n",
       "      <th>mentioned</th>\n",
       "      <th>Runs</th>\n",
       "      <th>Partei</th>\n",
       "      <th>model_predictions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1435940649572966400.0</td>\n",
       "      <td>CHARLYCAPRI4</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@SWagenknecht Sie sind gescheitert ,weil Sie d...</td>\n",
       "      <td>2022-03-31 23:51:42+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['SWagenknecht']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>528677411.0</td>\n",
       "      <td>jo711</td>\n",
       "      <td>6</td>\n",
       "      <td>308.0</td>\n",
       "      <td>Ewiger Revolluzer :-) ,\\nBiker,Hundeverrckt.N...</td>\n",
       "      <td>jo</td>\n",
       "      <td>@SWagenknecht Mittlerweile langweilen Sie .\\nK...</td>\n",
       "      <td>2022-03-31 23:51:27+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['SWagenknecht']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>762265140.0</td>\n",
       "      <td>nimmdenbus</td>\n",
       "      <td>1574</td>\n",
       "      <td>118892.0</td>\n",
       "      <td>Take the bus! Prenez le bus! Mein Herz schlgt...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@MarvinWendland1 @SWagenknecht @BinBerlinerIn ...</td>\n",
       "      <td>2022-03-31 23:50:40+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['MarvinWendland1', 'SWagenknecht', 'BinBerlin...</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>94034298.0</td>\n",
       "      <td>derstaatsanwalt</td>\n",
       "      <td>325</td>\n",
       "      <td>5762.0</td>\n",
       "      <td>Ius vigilantibus scriptum est | er/ihr | rt/fo...</td>\n",
       "      <td>Standort ausgeblendet</td>\n",
       "      <td>@voglerk @NiemaMovassat Mit Landleben hat das,...</td>\n",
       "      <td>2022-03-31 23:45:33+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['voglerk', 'NiemaMovassat']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3098650023.0</td>\n",
       "      <td>emerald_fm</td>\n",
       "      <td>99</td>\n",
       "      <td>45077.0</td>\n",
       "      <td>HOL' DIR DEINEN OHRWURM!\\n+49-30-92094422\\n...</td>\n",
       "      <td>Prusse Hrouge, Berlin, Germany</td>\n",
       "      <td>@DietmarBartsch Alles Gute zum 63sten noch, He...</td>\n",
       "      <td>2022-03-31 23:45:30+00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['DietmarBartsch']</td>\n",
       "      <td>Linke_polis_1</td>\n",
       "      <td>Die Linke</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150439</th>\n",
       "      <td>199995</td>\n",
       "      <td>3601292</td>\n",
       "      <td>1148916458983964673</td>\n",
       "      <td>DagmarFreitag13</td>\n",
       "      <td>1280</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>MdB 1994-2021  SPD   Transatlantikerin  Atl...</td>\n",
       "      <td>Iserlohn, Deutschland</td>\n",
       "      <td>@JoSteiniger Eins so schlecht wie das andere. ...</td>\n",
       "      <td>2022-03-14 12:49:31+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>['JoSteiniger']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150440</th>\n",
       "      <td>199996</td>\n",
       "      <td>3601294</td>\n",
       "      <td>1148916458983964673</td>\n",
       "      <td>DagmarFreitag13</td>\n",
       "      <td>1280</td>\n",
       "      <td>4085.0</td>\n",
       "      <td>MdB 1994-2021  SPD   Transatlantikerin  Atl...</td>\n",
       "      <td>Iserlohn, Deutschland</td>\n",
       "      <td>@JoSteiniger Unmittelbar nach der Flutkatastro...</td>\n",
       "      <td>2022-03-14 12:48:54+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['JoSteiniger']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150441</th>\n",
       "      <td>199997</td>\n",
       "      <td>3601295</td>\n",
       "      <td>1470993750252007425</td>\n",
       "      <td>BauingM</td>\n",
       "      <td>1302</td>\n",
       "      <td>10748.0</td>\n",
       "      <td>Leben und leben lassen.\\nGlaube nur der Statis...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jensspahn Die komplette Co2-Steuer gehrt abg...</td>\n",
       "      <td>2022-03-14 12:48:45+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>['jensspahn']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150442</th>\n",
       "      <td>199998</td>\n",
       "      <td>3601296</td>\n",
       "      <td>825765542816575489</td>\n",
       "      <td>SantorinRh</td>\n",
       "      <td>261</td>\n",
       "      <td>11781.0</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>@jensspahn Zum Ersten Mal bin ich der gleichen...</td>\n",
       "      <td>2022-03-14 12:48:10+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['jensspahn']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2150443</th>\n",
       "      <td>199999</td>\n",
       "      <td>3601299</td>\n",
       "      <td>3618908661</td>\n",
       "      <td>StefanHarders</td>\n",
       "      <td>594</td>\n",
       "      <td>18212.0</td>\n",
       "      <td>Engineer #ClimateEmergency #carfree #mdRzA #mo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@klaus66online @Scratchstone @jensspahn Spritp...</td>\n",
       "      <td>2022-03-14 12:46:29+00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>['klaus66online', 'Scratchstone', 'jensspahn']</td>\n",
       "      <td>CDUCSU_polis_3</td>\n",
       "      <td>CSU/CDU</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2150444 rows  18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index Unnamed: 0              author_id         username  \\\n",
       "0             0          1  1435940649572966400.0     CHARLYCAPRI4   \n",
       "1             1          2            528677411.0            jo711   \n",
       "2             2          3            762265140.0       nimmdenbus   \n",
       "3             3          4             94034298.0  derstaatsanwalt   \n",
       "4             4          5           3098650023.0       emerald_fm   \n",
       "...         ...        ...                    ...              ...   \n",
       "2150439  199995    3601292    1148916458983964673  DagmarFreitag13   \n",
       "2150440  199996    3601294    1148916458983964673  DagmarFreitag13   \n",
       "2150441  199997    3601295    1470993750252007425          BauingM   \n",
       "2150442  199998    3601296     825765542816575489       SantorinRh   \n",
       "2150443  199999    3601299             3618908661    StefanHarders   \n",
       "\n",
       "        author_followers  author_tweets  \\\n",
       "0                      1           14.0   \n",
       "1                      6          308.0   \n",
       "2                   1574       118892.0   \n",
       "3                    325         5762.0   \n",
       "4                     99        45077.0   \n",
       "...                  ...            ...   \n",
       "2150439             1280         4085.0   \n",
       "2150440             1280         4085.0   \n",
       "2150441             1302        10748.0   \n",
       "2150442              261        11781.0   \n",
       "2150443              594        18212.0   \n",
       "\n",
       "                                        author_description  \\\n",
       "0                                                      NaN   \n",
       "1        Ewiger Revolluzer :-) ,\\nBiker,Hundeverrckt.N...   \n",
       "2        Take the bus! Prenez le bus! Mein Herz schlgt...   \n",
       "3        Ius vigilantibus scriptum est | er/ihr | rt/fo...   \n",
       "4        HOL' DIR DEINEN OHRWURM!\\n+49-30-92094422\\n...   \n",
       "...                                                    ...   \n",
       "2150439  MdB 1994-2021  SPD   Transatlantikerin  Atl...   \n",
       "2150440  MdB 1994-2021  SPD   Transatlantikerin  Atl...   \n",
       "2150441  Leben und leben lassen.\\nGlaube nur der Statis...   \n",
       "2150442                                               \n",
       "2150443  Engineer #ClimateEmergency #carfree #mdRzA #mo...   \n",
       "\n",
       "                        author_location  \\\n",
       "0                                   NaN   \n",
       "1                                    jo   \n",
       "2                                   NaN   \n",
       "3                 Standort ausgeblendet   \n",
       "4        Prusse Hrouge, Berlin, Germany   \n",
       "...                                 ...   \n",
       "2150439           Iserlohn, Deutschland   \n",
       "2150440           Iserlohn, Deutschland   \n",
       "2150441                             NaN   \n",
       "2150442                             NaN   \n",
       "2150443                             NaN   \n",
       "\n",
       "                                                      text  \\\n",
       "0        @SWagenknecht Sie sind gescheitert ,weil Sie d...   \n",
       "1        @SWagenknecht Mittlerweile langweilen Sie .\\nK...   \n",
       "2        @MarvinWendland1 @SWagenknecht @BinBerlinerIn ...   \n",
       "3        @voglerk @NiemaMovassat Mit Landleben hat das,...   \n",
       "4        @DietmarBartsch Alles Gute zum 63sten noch, He...   \n",
       "...                                                    ...   \n",
       "2150439  @JoSteiniger Eins so schlecht wie das andere. ...   \n",
       "2150440  @JoSteiniger Unmittelbar nach der Flutkatastro...   \n",
       "2150441  @jensspahn Die komplette Co2-Steuer gehrt abg...   \n",
       "2150442  @jensspahn Zum Ersten Mal bin ich der gleichen...   \n",
       "2150443  @klaus66online @Scratchstone @jensspahn Spritp...   \n",
       "\n",
       "                        created_at quote_count retweets  replies  likes  \\\n",
       "0        2022-03-31 23:51:42+00:00           0        0      0.0    0.0   \n",
       "1        2022-03-31 23:51:27+00:00           0        0      0.0    0.0   \n",
       "2        2022-03-31 23:50:40+00:00           0        0      0.0    0.0   \n",
       "3        2022-03-31 23:45:33+00:00           0        0      0.0    0.0   \n",
       "4        2022-03-31 23:45:30+00:00           0        0      0.0    1.0   \n",
       "...                            ...         ...      ...      ...    ...   \n",
       "2150439  2022-03-14 12:49:31+00:00         0.0      0.0      0.0    0.0   \n",
       "2150440  2022-03-14 12:48:54+00:00         0.0      0.0      1.0    1.0   \n",
       "2150441  2022-03-14 12:48:45+00:00         0.0      1.0      0.0    8.0   \n",
       "2150442  2022-03-14 12:48:10+00:00         0.0      0.0      0.0    1.0   \n",
       "2150443  2022-03-14 12:46:29+00:00         0.0      0.0      1.0    1.0   \n",
       "\n",
       "                                                 mentioned            Runs  \\\n",
       "0                                         ['SWagenknecht']   Linke_polis_1   \n",
       "1                                         ['SWagenknecht']   Linke_polis_1   \n",
       "2        ['MarvinWendland1', 'SWagenknecht', 'BinBerlin...   Linke_polis_1   \n",
       "3                             ['voglerk', 'NiemaMovassat']   Linke_polis_1   \n",
       "4                                       ['DietmarBartsch']   Linke_polis_1   \n",
       "...                                                    ...             ...   \n",
       "2150439                                    ['JoSteiniger']  CDUCSU_polis_3   \n",
       "2150440                                    ['JoSteiniger']  CDUCSU_polis_3   \n",
       "2150441                                      ['jensspahn']  CDUCSU_polis_3   \n",
       "2150442                                      ['jensspahn']  CDUCSU_polis_3   \n",
       "2150443     ['klaus66online', 'Scratchstone', 'jensspahn']  CDUCSU_polis_3   \n",
       "\n",
       "            Partei  model_predictions  \n",
       "0        Die Linke                  0  \n",
       "1        Die Linke                  0  \n",
       "2        Die Linke                  0  \n",
       "3        Die Linke                  0  \n",
       "4        Die Linke                  0  \n",
       "...            ...                ...  \n",
       "2150439    CSU/CDU                  0  \n",
       "2150440    CSU/CDU                  0  \n",
       "2150441    CSU/CDU                  0  \n",
       "2150442    CSU/CDU                  0  \n",
       "2150443    CSU/CDU                  0  \n",
       "\n",
       "[2150444 rows x 18 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "435c0632-42ee-461b-bffe-1346eb03ac68",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../full_datasets/mentions_predicted.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8fa36b39-2cd6-4c50-86e7-380f508d9d18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1750146\n",
       "1     400298\n",
       "Name: model_predictions, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.model_predictions.value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
